%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[a4paper,czech,english,12pt,a4paper,czech,english]{report}
\usepackage[cp1250]{inputenc}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{babel}
\usepackage{verbatim}
\usepackage{prettyref}
\usepackage{wrapfig}
\usepackage{calc}
\usepackage{units}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Optimization of operation of renewable electric energy sources based on fuel cells, accumulators and PV panels for small powers},
 pdfauthor={Martin Holeèek}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\pdfpageheight\paperheight
\pdfpagewidth\paperwidth

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\setlength{\textwidth}{145mm}
\setlength{\textheight}{247mm}
\setlength{\oddsidemargin}{15mm}
\setlength{\evensidemargin}{15mm}
\setlength{\topmargin}{0mm}
\setlength{\headsep}{0mm}
\setlength{\headheight}{0mm}
\let\openright=\clearpage
%\ifx\uv\undefined\newcommand{\uv}[1]{,,#1``}\fi
\usepackage{amsthm,amsmath,amssymb,amscd,mathrsfs,url}
%\usepackage[czech]{babel}
%\usepackage[utf8]{inputenc}
\usepackage[cp1250]{inputenc}
\usepackage{verbatim}
%\usepackage{ictamxs}
\usepackage{showkeys}
\usepackage{xcolor}
\usepackage{stackengine}
\usepackage{lipsum}
\usepackage{comment}
%%\usepackage{MNsymbol} NIKDY!
\usepackage{graphicx}
\usepackage{caption}
\usepackage{nomencl}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage[customcolors,shade]{hf-tikz}
\usepackage{marginnote}
\usepackage{esint}
\usepackage{ulem}
\usepackage{multicol}%%% vícesloupcová sazba
\usepackage{fancybox}%%% vkládání obrázkù
\usepackage{psfrag}
\usepackage{fancyvrb}
\usepackage{bbding}
\usepackage{comment}
\usepackage{epstopdf} 
\usepackage{url}
\usepackage{natbib}
\DeclareGraphicsExtensions{.pdf,.eps,.png,.jpg,.mps}

\setcounter{secnumdepth}{0}

\numberwithin{table}{chapter}
\numberwithin{figure}{chapter}
\numberwithin{equation}{chapter}

\newcommand{\opdiv}{\mathop{\mathrm{div}}}
\newcommand{\oprot}{\mathop{\mathrm{rot}}}

\newcommand{\FIGDIR}{./Obrazky}    %%% cesta do adresare s obrazky

\newcounter{definice}
\numberwithin{definice}{chapter}
\renewcommand{\thedefinice}{\arabic{chapter}.\arabic{definice}}
\newenvironment{definice}[1][]{
  \refstepcounter{definice}
  \par\medskip\noindent
  \textbf{Definice \thedefinice #1}.
}{
}

\newcounter{veta}
\numberwithin{veta}{chapter}
\renewcommand{\theveta}{\arabic{chapter}.\arabic{veta}}
\newenvironment{veta}[1][]{
  \refstepcounter{veta}
  \par\medskip\noindent
  \textbf{Vìta \theveta #1}.
  \itshape
}{
}

\newenvironment{dukaz}{
  \par\medskip\noindent
  \textit{Dùkaz}.
}{
\newline
\rightline{\SquareCastShadowBottomRight}
}


\DefineVerbatimEnvironment{PCinout}{Verbatim}{fontsize=\small, frame=lines}
\DefineVerbatimEnvironment{PCinoutsmaller}{Verbatim}{fontsize=\smaller, frame=lines}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\Natu}{\mathbb{N}}

\DeclareMathOperator{\Prob}{\textsf{P}}
\DeclareMathOperator{\EV}{\textsf{E}}
\DeclareMathOperator{\var}{\textrm{var}}
\DeclareMathOperator{\sd}{\textrm{sd}}

\newcommand{\betab}{\boldsymbol{\beta}}
\newcommand{\thetab}{\boldsymbol{\theta}}
\newcommand{\varepsilonb}{\boldsymbol{\varepsilon}}

\newcommand{\xb}{\boldsymbol{x}}
\newcommand{\yb}{\boldsymbol{y}}
\newcommand{\Xb}{\boldsymbol{X}}
\newcommand{\Yb}{\boldsymbol{Y}}

\newcommand{\Xm}{\mathbb{X}}

\renewcommand{\t}[1]{#1^\top}  
\bibliographystyle{alpha}
\usepackage{ae}
%\hyphenation{troj-ú-hel-ník nic-mé-nì pøed-in-te-gro-vá-ní pøí-pa-dì pøe-cho-do-vé uva-žo-va-né na-pøí-klad na-po-èí-ta-nou po-ža-du-je-me umož-ní-me mat-lab-u}
\makenomenclature

\makeatother

\begin{document}
\include{dp_titulni}


\chapter*{Motivation and introduction}

\setcounter{chapter}{1}
\addcontentsline{toc}{chapter}{Motivation and Introduction}

For better understanding of the whole problem and work, lets imagine
a model situation, that we can follow. Lets say, we want to make an
energy independent unit - ecologic house, for example.

Lets add renewable energy source (photovoltaic panels) and a system
for storing energy. Batteries alone are not sufficient, because they
would need to be changed, due to degradation. So lets add availible
hydrogen technologies - electrolyzer, hydrogen tank, fuel cells. And,
to finish the setting, backup energy unit (or electric grid). The
goal is to determine the system parameters (and develop the strategy
to do so) and power managment strategy in a manner to make the system
independent as much as possible (minimizing the consumption of backup
energy or energy from grid).

\begin{comment}
In this work not only do we want to solve this problem, but also to
make this text usefull for future coworkers,
\end{comment}


For now, lets look at the theoretical and practical tools needed to
solve this problem in the following part ``research and previous
works''. Later we will return to our model problem, and we will use
the tools to analyze the setting and rewrite it into mathematical
formulation. 

Lastly, there will be a brief note about the developed algorithms.

\begin{comment}
At our disposition we will have (or will develop) model for the system
with equations for parts of the system and supplying datas for daily
light current and energy demand.
\end{comment}
\begin{figure}[b]
\includegraphics[width=0.45\textwidth]{Schema-copy}\includegraphics[width=0.45\textwidth]{instalace}\protect\caption{Schema of functional units (left) and a photo of existing installation
in ÚJV Øež (right) \cite{UJVInst}}
\end{figure}



\chapter*{Research and previous works}

\setcounter{chapter}{2}
\addcontentsline{toc}{chapter}{Research and previous works}

Lets look at other works and summarize concepts from the relevant
fields.


\section{Optimization and hydrogen technology}

Fuel cells and hydrogen technologies (as a part of renewable resources
\cite{RenewableSources}), extend the possibilities of energy storage
\cite{EnergyAccumulation} and create a possibility for research of
various systems using mathematical tools to model and optimize these
systems. One example of such a system are standalone energetic units
\cite{MassimoStandalone}.

Some possibilities of optimization of these standalone systems are
summarized in \cite{ErdincOptimumDesign}, optimization of standalone
energetic units and power managment strategies are being researched
too (in, for example \cite{IpsakisPowerManagmentStrategies}), and
some works are also focused on specific installations \cite{Abdelkafi20141},
\cite{Sarioglu20147}, \cite{Taher2014268}, \cite{Cai2014212}. Also
optimization problems are solved for vehicles \cite{Maalej2014668}.
In the article \cite{CaliseSingleLevel}, there is proposed an optimal
system even for the powerplant of SOFC (solid oxide fuel cell) type.
Practical measurements of standalone systems efficiency are described
together with theoretical background in \cite{VyrobaAVyuziti}.

From the other side, practical application of optimization in the
theory of optimal control is described in the books \cite{EvansControlCourse},
\cite{Lewis2012optimal}, \cite{Warga1972optimal}. An example of
a method used for global optimization is an application of metropolis
algorithm, so called Simulated annealing \cite{SimulatedAnnealing}
(that was originally used for the design of electric circuits or in
chemistry \cite{Chaudhuri1997733}). There is even a method taking
in account the uncertainity of data, called Stochastic annealing \cite{PaintonStochastic}.
This method is used in \cite{GiannakoudisOptimumDesign} for optimization
of the parameters of a control strategy.

Another interesting optimization principle, the Pontryagin principle,
is used to prolong the lifetime of such systems \cite{XuPontryaginStrategy,ProlongingLifetime,ZhengPontryaginProlonging}.

Needed to say, that new algorithms of global optimization are often
being used (ex. particle swarm, or genetic algorithms). For these
algorithms, the question of convergence is still an open problem (about
this and another possibilities of such algorithms see the text \cite{ExperimentalAlgorithms}). 




\paragraph*{}


\section{Models for batteries, fuel cells, electrolyzer, photovoltaics...}

There are rich availible model descriptions (for example also in \cite{vepa2013dynamic}),
complex models (with PDEs) are used for complicated problems and for
detailed desription of inside processes (for example in a battery),
but these models aren't meant and suited for simulations taking longer
time or scale. More simple models with less variables (for example
like curve fitting) are better in case in which we do need to evaluate
the model more times per run (as in our case).


\subsection{Photovoltaics}

When looking at photovoltaic (PV) panels, if we want a better model
than just saying ``general power source\textquotedbl{}, we need to
consider that the photoelectric effect (the power source) happens
at the P-N junction, which is, of course, a diode, and that there
is also some ressistance present. Thats the reason, why the following
(\ref{fig:5-parameter-equivalent}) equivalent circuit - ``5 parameter
circuit\textquotedbl{} - is used (there exists even the so called
``7 parameter circuit\textquotedbl{} which has another diode in parallel
to the first diode). 

\begin{wrapfigure}{O}{0.5\columnwidth}%
\includegraphics[width=0.4\textwidth]{275px-Solar_cell_equivalent_circuit\lyxdot svg}\protect\caption{\label{fig:5-parameter-equivalent}5 parameter equivalent circuit
for photovoltaic panel}
\end{wrapfigure}%
Construction details, like material used (single crystalline silicon,
polycrystalline and semicrystalline, thin films, amorphous silicon,
spheral...) or additional tricks (concentrated cells, lens, antireflexive
and other coating) affect the parameters and the efficiency. 

The circuit supplies current $I=I_{pv}$ at voltage $V=V_{pv}$, $I_{L}$
is generated current by photovoltaic effect and from that we subtract
diode current and shunt current. This way we can derive the model:
\begin{itemize}
\item $I_{pv}=I_{L}-I_{D}-I_{sh}=I_{L}-I_{0}(\exp(\frac{V_{pv}+I_{pv}R_{s}}{\alpha}))-\frac{V_{pv}+I_{pv}R_{s}}{R_{sh}}$\nomenclature{$I_{pv}$}{Current from photovoltaic model circuit ($A$)}
\item $I_{L}=C_{1}G,\,I_{0}=C_{2}T^{3}\exp(\frac{-E_{GO}}{kT})$
\item $P_{pv}=V_{pv}I_{pv}\eta_{conv}$ \nomenclature{$P_{pv}$}{Power from photovoltaic model circuit ($J$)}
\item $\alpha$ curve fitting parameter (model requires test runs and measurements)
\item $G$ incident radiation \nomenclature{$G$}{Incident radiation ($W/m^2$)}
\item $T$ surface temperature (in kelvins)
\item $E_{GO}$ band gap of the used PV material \nomenclature{$E_{GO}$}{band gap of the used PV material}
\item $C_{i}$ constants
\item $I_{L}$light current\nomenclature{$I_L$}{light current $A$}
\item $I_{D}$diode current \nomenclature{$I_{D}$}{diode current $A$}
\item $I_{sh}$shunt current \nomenclature{$I_{sh}$}{shunt current $A$}
\item $I_{0}$diode reverse saturation current (comes from the Shockley's
diode equation) \nomenclature{$I_{0}$}{diode reverse saturation current $A$}
\item $V_{pv}$, $I_{pv}$, operational voltage and current \nomenclature{$V_{pv}$}{operation voltage (photovoltaic) $V$}
\item $R_{s}$, $R_{sh}$, parallel and shunt ressistors \nomenclature{$R_{s}$}{parallel resistor ressistance $Ohm$}\nomenclature{$R_{sh}$}{shunt ressistor ressitance $Ohm$}
\item $P_{pv}$, $\eta_{conv}$ output power and effectivity \nomenclature{$\eta_{conv}$}{effectivity of photovoltaic output power}
\end{itemize}
Parameters commonly used to characterize the output of the unit are:
short circuit current, open circuit voltage and maximum power point.
Nice derivation is in the work \cite{Stand-alonePowerSystems} together
with a method on how to compute the parameters from manufacturer supplied
information from datasheet, notes on behavior with changing temperature,
and finally even a fortran code for PV panels. 

In a work focused on solar panels and water electrolysis \cite{olubukunmi2011solar},
there is deeper description and analysis and measurement of output
power dependency on illumination and even thermal effects. The efficiency
of PV energy generation is said to be from 5 to 20\%.

Needed to say, that detailed analysis of output power includes an
observation \cite{voutetakis2011design}, that there is a maximal
power point in the voltage current characteristic; this is ideally
exploited by a microcontroller, traking this point. (In addition this
book covers many interesting details, even about AC/DC converters.)
Algorithms for tracking maximal power point are also being developed
in \cite{beyer2004robust,salas2006review}, also using neural networks
is considered \cite{caluianu2011photovoltaic}.






\subsection{Battery}

Why to use both batteries and hydrogen (tanks) to store energy? Batteries
have higher efficiency, but can not store as much energy as we can
with hydrogen. Moreover, the state of charge of batteries tends to
decrease and batteries tends to lose quality over time. But using
them as quick source, or buffer of energy, is generally a good idea.
Moreover, in a case, where electrolyzer works more efficiently at
lower loads, battery can lower the load by taking it on itself.

\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics[scale=0.2]{EqivLeadAcid}\protect\caption{Equivalent circuit for lead acid accumulator.}
\end{wrapfigure}%


The main variables for a common battery model are the voltage and
state of charge (SOC). Lets speak about a model of lead acid accumulator
from \cite{voutetakis2011design} - the model is generally valid for
batteries charged more than 20 \%, has relations for charging and
discharging and is parametrized by parameters that need to becomputed
experimentally. (Needed to say, that there exist models even for overcharged
batteries and other specific cases.)

\[
I_{bat}=I_{q}-\frac{Q_{bat,nom}}{10}g_{0}exp(\frac{V_{cell}}{g_{1}}-\frac{g_{2}}{T_{bat}})
\]
\nomenclature{$I_{bat}$}{battery current $A$}

The battery current is the reaction current ($I_{q}$) minus the gas
current losses, that are modelled using nominal capacity of accumulator
($Q_{bat,nom}$ in $Ah$), cell voltage, temperature and gassing current
parameters. The cell voltage is the equillibrium voltage plus polarization
voltage:

\[
V_{cell}=V_{equ,0}+\frac{V_{equ,l}SOC}{100}+V_{pol}
\]
\nomenclature{$V_{cell}$}{cell voltage $V$}

The equillibrium voltage is approximated linearily by its value at
$SOC=0$ and slope $V_{equ,l}$, the polarization voltage is different
for charging and discharging (with coefficients dependent on the battery):

\begin{eqnarray*}
V_{pol,ch} & = & U_{ch}a_{ch}(1-\exp(-\frac{I_{q,norm}}{b_{ch}})+c_{ch}I_{q,norm})\\
V_{pol,dch} & = & U_{dch}(1-\exp(-\frac{I_{q,norm}}{b_{dch}})+c_{dch}I_{q,norm})(1+(g_{100}-1)\exp(\frac{SOC-100}{k_{100}}))
\end{eqnarray*}
\nomenclature{$V_{pol,ch}$}{charging polarization voltage $V$}\nomenclature{$V_{pol,dch}$}{discharging polarization voltage}

The indexes ``ch\textquotedbl{} stand for charging and ``dch\textquotedbl{}
for discharging. The parameters $g_{100},k_{100}$ are height and
slope parametes for fully charged battery ($SOC=100\%$).

A discrete model for a capacity of the battery is 
\[
Q_{bat,i}=Q_{bat,i-1}+I_{q}(t_{i}-t_{i-1})=Q_{bat,nom}SOC_{i-1}/100+I_{q}(t_{i}-t_{i-1})
\]
\nomenclature{$Q_{bat.i}$}{battery capacity $J$}

The state of charge of the accumulator is a fraction of the current
capacity at each time instant divided by its nominal capacity. So
for $SOC$ we have a model with efficiency ($\eta_{ac}$)\nomenclature{$\eta_{ac}$}{battery efficiency},
discharge rate ($\sigma_{ac}$)\nomenclature{$\sigma_{ac}$}{battery discharge rate}
and charge or discharge current $I_{ac}$\nomenclature{$I_{ac}$}{battery current (charge or discharge)}.

\[
SOC(t+1)=SOC(t)(1-\sigma_{ac})+I_{ac}\eta_{ac}(\Delta t)
\]


$SOC$ cannot be directly measured, it needs to be derived from the
model or indirectly from experiements.\nomenclature{$SOC$}{battery state of charge}




\subsection{Electrolyzer and Fuel cell}

Electrolyzer and fuel cell both basically operate from a simple chemical
reaction (\cite{rayment2003introduction}) :

\[
H_{2}O\longleftrightarrow H_{2}+\frac{1}{2}O_{2}
\]


By adding (electric) power, the reaction occurs from left side to
the right, producing hydrogen and oxygen, whereas combining hydrogen
and oxygen allows us to get the energy back. The first way is the
basic function of electrolyzer and the latter is of the fuel cell.
By Faradays law, the (molar) quantity of produced/consumed hydrogen
is proportional to transfered charge.

Interesting details arise from the exact engeneering of both processes
(parameters like temperature, material of electrolyte or membrane,
catalyzators etc...), anyway the basic common variables are voltage,
current and temperature.

It is good to note, that hydrogen has the best heating value (energy
to fuel ratio). The higher heating value is $142.12\,MJ\,kg^{-1}$,
the pure standard heat formation of the product water. The lower heating
value is $120.21\,MJ\,kg^{-1}$, calculated from the fact, that the
product oxygen goes out unused as a steam (at said $150$ \textdegree C
). Electrolysis is not the only way to get hydrogen, other ways are
being considered too, for example by reforming natural gases.


\subsubsection{Electrolyzer}

Common types of electrolyzers are alkaline based (operates using an
alkaline solution) and proton exchange membrane electrolyzer (PEM).

As presented in \cite{voutetakis2011design}, there are many ways
that lead to the voltage-current model of the electrolyzer: regression,
models based on analysis of processes on anothe, cathode and membrane
(and calculating then V-I relationship by subtracting from the open
circuit voltage the voltages of activation polarization and ohmic
polarization), and even rigorous CFD models.


\subsubsection{Butler Volmer equation}

In the work \cite{Stand-alonePowerSystems}, it is noted, that at
low voltages, the electrolyzer is more efficient, but generates small
amounts of hydrogen. The Butler-Volmer equation is used to model the
system:

\[
I=I_{0e}(\exp(\frac{(1-\alpha_{e})n_{e}F}{RT}(U-U_{eq}))-\exp(-\frac{\alpha_{e}n_{e}F}{RT}(U-U_{eq})))
\]


With unknown parameters $I_{0e}$, $\alpha_{e}$ (symmetry factor)
and$U_{eq}$. Hydrogen production rate is computed as follows: \nomenclature{$n_{H_2}$}{hydrogen production rate ($\frac{mol}{hr \cdot A}$)}

\[
n_{H_{2}}=\frac{N_{cell}I_{elec}}{n_{e}F}\eta_{F}
\]
\nomenclature{$N_{cell}$}{number of cells}\nomenclature{$I_{elec}$}{current through electrolyzer $A$}\nomenclature{$\eta_F$}{Faraday efficiency}

where $F$ is Faraday constant and $\eta_{F}$ is Faraday efficiency
(relation between theoretical and actual electron transfer, often
to be determined by experimental measure), $n_{e}=2$ \nomenclature{$n_e$}{Electrons in $H_2$}.



\paragraph{One empirical model}

\[
V_{elec}=V_{rev,elec}+\frac{r_{1}+r_{2}T}{A_{elec}}I_{elec}+(s_{1}+s_{2}T+s_{3}T^{2})\log(\frac{t_{1}+t_{2}/T+t_{3}/T^{2}}{A_{elec}}I_{elec}+1)
\]
\nomenclature{$V_{elec}$}{electrolyzer voltage $V$}\nomenclature{$A_{elec}$}{area of electrolyzer $m^2$}

This model primary expresses dependency on temperature (\cite{voutetakis2011design}).
There exists even empirical model for the faraday's efficiency, that
also accounts for the fact, that with decreasing current and/or higher
temperatures, the parasitic currents increase (because of the electrolyte).

\[
\eta_{F}=B_{1}+B_{2}\exp(\frac{B_{3}+B_{4}T_{el}+B_{5}T_{el}^{2}}{i})
\]
\nomenclature{$i$}{area current $A/m^2$}




\subsubsection{Fuel cell}

The exact process in fuel cell happens in this way:

\begin{eqnarray*}
H_{2} & \rightarrow & 2H^{+}+2e^{-}\\
\frac{1}{2}O_{2}+2e^{-} & \rightarrow & O^{2-}\\
2H^{+}+O^{2-} & \rightarrow & H_{2}O
\end{eqnarray*}


And the calculation (from \cite{olubukunmi2011solar}) for the amount
of hydrogen produced is:

\[
n_{H_{2}}=\frac{1}{\epsilon}\cdot0,01866\frac{mol}{hr\cdot A},\,m_{H_{2}}=\frac{1}{\epsilon}\cdot3,77\cdot10^{-5}\frac{kg}{hr\cdot A}
\]
\nomenclature{$m_{H_2}$}{hydrogen production rate (kilograms instead of mols) $\frac{kg}{hr \cdot A}$}...
where $\epsilon$ is the fuel cell efficiency:

The simplest way to model fuel cell V-I relationship is to look at
it as a reverse electrolyzer, this way is followed by the following
model from \cite{voutetakis2011design}.


\paragraph{First empiric model}

Takes into account the overvoltages (ohmic and activation), but not
effects of mass. The model computes the cell voltage $V_{fc}$\nomenclature{$V_{fc}$}{fuel cell voltage $V$}
using open circuit voltage $V_{o}$\nomenclature{$V_{o}$}{open circuit voltage for fuel cell $V$},
current density $i$ (in $A/m^{2}$), model parameter $b$, current
at the inflection point of the V-I curve $I_{d}$ and slope $\Delta$
at the linear stage of ohmic overvoltage:\nomenclature{$I_{d}$}{current at inflection point in fuelcell V-I curve }

\[
V_{fc}=E+\frac{b}{\ln(1/I_{d}\,i)}-(\Delta-\frac{b}{4I_{d}})\,i
\]


The parameters ($K\in\{E,\,I_{d},\,b,\,\Delta\}$) \nomenclature{$K$}{general notation for one parameter in empiric model for fuelcells}
vary with fuel cell temperature $T$ and oxygen partial pressue $p_{O_{2}}$:\nomenclature{$p_{O_2}$}{oxygen partial pressue}

\[
K=K_{1}+K_{2}T+K_{3}T\ln(p_{O_{2}})
\]


It is said, that this model is suitable more for low voltages and
powers. But it can be used even for electrolyzer ($p_{O_{2}}$ is
then the operating pressue for the electrolyzer at which the oxygen
is produced).


\paragraph{Second empiric model}

This model takes into effect even the mass transport limitation. For
computation of a cell voltage $V_{fc}$ and open circuit voltage $V_{o}$,
the following applies:

\begin{eqnarray*}
V_{fc} & = & V_{o}-a_{T}\log(i)-ir+m\exp(il)\\
V_{o} & = & V_{rev,FC}+B\log(i_{o})
\end{eqnarray*}


Where $V_{rev,FC}$ \nomenclature{$V_{rev,fc}$}{fuelcell, reversible voltage}is
the reversible voltage, $i$ the current density (fuel cell current
per unit area of the electrode, in units of milliamps per square centimeter),$i_{0}$
and $B$ the Tafel parameter ($i_{0}$is the value on the Tafel plot
when the current begins to move away from zero), $a_{T}$ the Tafel
slope, $r$ the resistance (in $\Omega\cdot cm^{2}$), and finally
the model parameters $m$, $l$ representing the overvoltage due to
mass transport limits. All these parameters can depend on temperature.

Hydrogen and oxygen then flows according to this equations (by Faradays
law, already substitued $n_{e,H_{2}}=2,\,n_{e,O_{2}}=4$):

\[
H_{2,g}=\frac{N_{cell}I}{2F\eta_{F}}\,mol/s,\,O_{2,g}=\frac{N_{cell}I}{4F\eta_{F}}\,mol/s
\]


All these models are empirical and are important because of their
low computational complexity. For greater complexity, there are, of
course, more sophisticated models using partial differential equations.
For more in depth description, there is also a book about fuel cells,
that examines every aspect of fuel cell design and explains the details
of how fuel cells work \cite{larminie2003fuel}.

Lets add a word about the storage of hydrogen. The possibilities for
storage are to store it at the output pressue of the electrolyzer,
or at higher pressue or liquidified. These possibilities are covered
in most of presented resources and citations. If we wanted to store
the hydrogen in any other way, than at the output pressue, we would
need to add the compressor into the equation (like it is done in \cite{voutetakisdesign}).




\section*{\pagebreak{}}


\section{Optimization and optimal control}



Optimization is a rich field with many subproblems arising from the
specific problem settings. Optimal control is actually applied optimization
together with variational calculus \cite{milyutin1999calculus} and
has similar subproblems (or subclasses).

As (global) optimization is concerned about finding the minimum of
a function with number of parameters, optimal control theory takes
this idea to the next step and solves minimum of a functional (``objective
function'' or ``cost function\textquotedbl{} $J$ that consists
of final time objective and integrated Lagrangian) of a dynamic system,
evolving in time, controlled by a function (system dynamics).

\begin{align*}
\mbox{minimize}\,J & =\phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt\tag*{...cost function / objective function}\\
\dot{x} & =f(x,u,t)\tag*{...system dynamics}\\
x(0) & =x_{0}\\
g(x,u,t) & \leq0\tag*{...constraints}
\end{align*}


In free final time case, the function $\phi$ is not present.

Problems from calculus of variations can be formulated as an optimal
control problem, so the ideas from this field apply in optimal control
too. Moreover, optimal control theory has methods for solving the
problem of controllability and observability and the presence of noise.


\subsubsection{Basic terms}

Optimization problems have many subclasses (\ref{fig:Optimization-Tree})
and optimal control is not an exception.\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics[width=0.5\textwidth]{treeoptimiz}\protect\caption{\label{fig:Optimization-Tree}Optimization Tree, neos.mcs.anl.gov}
\end{wrapfigure}%




So, in formulating the problem, there are many decisions that need
to be made, or many features, that can be adressed. To get a grasp
of the field, lest summarize the most common features. (More details
can be found in the book \cite{bertsekas1995dynamic}, the developement
of this field over time is summarized in the article \cite{sargent2000optimal}).

First, the problem can be formulated in \textbf{finite time} or \textbf{infinite
time}, or the \textbf{time can be varied} too (``free time, fixed
endpoint'' problem vs ``fixed time free endpoint''). The model
can be\textbf{ continuous} or \textbf{discrete}, not only in \textbf{time,
but also in states}. Lastly, we can account for \textbf{statistical
uncertainities}. When we add probabilty to the problem, we will be
dealing with markov chains theory.

The goal, control policy, can be made \textbf{open loop} or \textbf{closed
loop} formulation. Closed loop does care for values and decisions
in intermediate states, whereas open loop control has the control
function predetermined in advance and does not rely on intermedate
states and values. Methods for solving optimal control problems are:
\textbf{dynamic programming}, \textbf{Hamilton Jacobi Bellman (HJB)
equations} and \textbf{Pontryagin maximum principle} (or minimum principle
... is called by both names in literature). Only some of the problems
can be solved analytically, for example the class of \textbf{linear
quadratic control} problems, that can be solved through Riccati equations.

Long story short, there are two main approaches - direct methods and
indirect methods. Indirect methods take the optimal control problem
and reformulate it as differential equation problem with possible
boundary conditions - this approach is best used for continuous functions,
of course. Direct methods, on the other hand, would see the problem
as a problem of nonlinear programming

Both approaches are supported by the strength of calculus of variations
\cite{gelfand1964calculus} and both approaches are actually used
in numerical solutions.


\subsubsection{Hamiltonian of the system}

Many problem formulations could be efficiently written using Hamiltonian
of the system. We will use it too, so lets state the Hamiltonian as
a Lagrangian (from cost function) plus adjoint variable times system
dynamics, how the Hamiltonian is usually defined:

\begin{eqnarray*}
H(x,u,\lambda,t) & = & L(x,u,t)+\lambda^{T}f(x,u,t)
\end{eqnarray*}


Said efficiency comes from the fact, that the system dynamics is a
sort of a constraint and we translate constrained optimization problem
to unconstrained - the adjoint variable comes from this idea to introduce
lagrangian multipliers (as in \cite{EvansControlCourse,Lewis2012optimal,bryson1975applied})
or from HJB equations. There are two ways to get the equations presented
later, one gives the name ``adjoint variable\textquotedbl{} to one
of the derivatives, so it is conveniet to use the name. It is essential
for formulations, that will come later. Lets just note here, that
Hamiltonian is constant for systems with parametres independent on
time.

To summarize, the problem is then to optimize the value of Hamiltonian
- finding such optimal control function $u$, state function $x$
and costate function $\lambda$.\nomenclature{$u$}{usuall notation for control function}\nomenclature{$x$}{usuall notation for state}\nomenclature{$\lambda$}{usual notation for costate}


\subsubsection*{Dynamic programming}

Dynamic Programming is a principle well known for problems, that can
be decomposed into smaller subproblems. The principle is easy - if
the optimal solution of a problem can be composed from optimal solutions
of subproblems, we can use this information to build the solution.
Whenever this is true (needs, for example, additive cost function),
we just dont need to search the whole state space, but we can construct
the solution by constructing subsolutions one from another in a clever
order. Like, for example, the problem of finding the shortest path
in a graph.

Dynamic programming needs discretized problem formulation. Ultimately,
going to the limit with discretization points gives rise to the HJB
equations.


\subsubsection{Hamilton-Jakobi-Bellman equations}

HJB eqs. are partial differential equations of the problem (here we
need the Hamiltonian), the last equation is just system dynamic written
using Hamiltonian:

\begin{align*}
J^{\star}(x(T),T) & =\phi(x(T),T)\\
-\frac{\partial J^{\star}}{\partial t} & =\min_{u}H(x,u,J_{x}^{\star},t)=\min_{u}H(x,u,J_{x}^{\star},t)=L(x,u,t)+J_{x}^{\star}f(x,u,t)\\
\dot{x} & =\frac{\partial H}{\partial\lambda}=f\tag*{...state equation}
\end{align*}


When using this apporach, the first step to solve is to get the optimal
value function first and from that the other values.

Hamilton-Jakobi-Bellman equations from optimal control gave life to
the theory of viscosity solutions (more can be found in the articles
\cite{bardi2008optimal,dragoniintroduction,liu2013introduction}.)
These equations can be solved using finite element methods, but their
numerical stability is said to not be good in practise.


\subsubsection{Pontryagin principle of maximality, PMP}

The last step - or method - is principle of maximality (Pontryagin
principle of maximality, PMP) and can be - for continuous control
functions - derived using the HJB equations (as in \cite{bertsekas1995dynamic}).
Using that, we get to formulate equations for adjoint variable - the
first equation is pontryagin maximum principle and the second we get
by differentiating HJB equation, as in \cite{diehl2011numerical}.
The last condition is the transversality condition for fixed time
free endpoint problem.



\begin{align*}
u^{\star}(t,x,\lambda) & =\arg\min_{u}(H(x,u,\lambda,t))\phi(x(T),T)\\
-\dot{\lambda} & =\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\\
\lambda(T) & =\nabla\phi(x(T),T)
\end{align*}




As was said, we get the same results even from the perspective of
taking the system dynamic as constraint for lagrange multipliers.

In the presence of state constraints $x\in R=\{x\in\mathbb{R}^{n},\,g(x)\le0\}$,
PMP is formulated a bit differently \cite{EvansControlCourse} - we
need to define a function 
\[
c(x,u)=\nabla g(x)\cdot f(x,u)
\]
 and the costate equation becomes: 
\[
-\dot{\lambda}=\frac{\partial H}{\partial x}(x,u,t)+\mu\frac{\partial c}{\partial x}(x,u)
\]
While the PMP now states the existence of the function $\mu:\,[0,T]\rightarrow\mathbb{R}$.

Needed to say, that PMP equations are only necessary condition for
optimality, so analytical proof of existence and uniqueness is needed.


All these analytic methods will give us equations, to solve the equations
is a concern of numerical optimal control.


\subsection{Numerical optimal control}

Numerical optimal control can be, again, used to solve either continuous
or discretized problems. Heavily relies on the problem analysis and
follows the said methods. It would seem, that it is sufficient to
just solve HJB PDR's, but it is not used everytime. For example, the
problem is, so called, curse of dimensionality - when state and/or
control, has many components, the problem becomes exponentially hard
to solve. Suggested remedy, in the article \cite{diehl2011numerical},
is, for example, to approximate value function by another means, for
example using neural network methods.  Second clue, to know when
to use state and costate equations, is, that when we want to have
continuous control function, we can just solve the boundary value
problem (as in, for example, \cite{wang2009solving}). When we want
to allow discontinuities, we need to rewrite the problem to nonlinear
optimization problem (an excellent book about this topic is \cite{chachuat2007nonlinear}).



\begin{figure}
\fbox{\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item HJB Equations - tabulation in state space
\item Indirect methods, Pontryagin - solve boundary value problem
\item Direct Methods - change to nonlinear programming

\begin{itemize}
\item Single shooting - discretized controls to NLP
\item Multiple shooting - controls and node start values discretized
\item Collocation - disretized controls and states\end{itemize}
\end{itemize}
%
\end{minipage}}

\protect\caption{Numerical optimal control cases}
\end{figure}


As said above, the main classes are \textbf{indirect methods} (first
optimize then discretize) and \textbf{direct methods} (first discretize,
then optimize). Indirect methods result in algorithms similar to ODE
solvers, but the resulting system can be badly conditioned or unstable
in some cases. Direct methods just rewrite the problem to the area
of nonlinear programming problem and then apply convenient solver.

There are three main cases of direct methods - single shooting, Multiple
shooting and collocation.

Single shooting discretizes the control to piecewise constant function
and uses numerical integrator for the evaluation of the cost function
(ODE). This way we get a finite dimensional optimization problem,
which can be solved by any nonlinear programming algorithm \cite{OptcontrNLP},
more in section below.

Single shooting algorithm is usefull, but the stability can sometimes
depend heavily on starting value.

Collocation discretizes both the control function and state function
and approximates the integral. We get larger system for nonlinear
programming, but the good news is that the system is sparse (in the
meaning, that the Jacobian has many zero elements). Collocation can
treat better even unstable systems, but refining the grid results
in new problem with higher dimensions.

Multiple shooting discretizes the control, as single shooting, and
additionally the time scale. So it is called ``multiple'' shooting,
because it works like running single shooting algorithm repeatedly
again from the starting times $t_{i}$. Of course we need to add constraints
for continuity (the end values from the previous interval to be the
same as the starting values on the next interval). Multiple shooting
algorithm results in only a block sparse problem, but is easy to paralelize
and can treat even unstable systems well.

Numerous implementations of numerical optimal control are availible,
not only in MATLAB, but for example also in C++ in \cite{Houska2011a}.


\paragraph{Nonlinear programming (NLP)}

Is an area of algorithms for optimizing nonlinear cost functions (on
constrained and unconstrained sets). Methods include derived algorithms
from ideas of gradient descend or newton method (applied on finding
a point where the gradient is zero), for example. Usually these methods
can also make use of derivatives (with said newton method on forst
derivative we, for example, need also second derivatives) and that,
in case of optimal control and optimizing differential equations,
leads to the need of computing sensitivity equations. That means how
the functional depends on the choice of (discretized) control function
$\frac{\partial J}{\partial u_{i}}$. When not supplied, methods usually
compute these just by approximating. Algoritmical approaches for getting
the results for sensitivity are, for example External Numerical Differentiation
(END), Variational Differential Equations, Automatic Differentiation,
Internal Numerical Differentiation (IND) (that makes use of the equations
written directly in source code for numerical computation).

More details about computing sensitivity equations are for example
in \cite{Sensitivity20061553}.

A suggested technique for solving optimal control problems is, for
example, Sequential quadratic programming, SQP, \cite{boggs1995sequential},
\cite{ottanumerical}. It is a method for solving nonlinear problems
with second derivatives; uses repeated subsolutions of quadratic programming
problems.

\pagebreak{}


\chapter*{Solution}

\setcounter{chapter}{3}
\addcontentsline{toc}{chapter}{Solution}

In this section we will apply the theory and methods to our setting
and problem (trying to focus on issues, that were not answered elsewhere).


\paragraph{Contribution of this work}

Now, lets emphasize, that other existing works tried to model the
problem using discontinuous functions and optimized only the system
parameters (for minimial cost) for given power managment strategy
or optimized only the the power managment strategy (or decision constants
of the said strategy).

So our aim will be to optimize the global parameters against the cost
(using global optimization algorithms) but for each test case (values
of variables) use the methods of optimal control theory to find the
best control strategy. That can be usefull in cases, where we wonder
about the following:
\begin{itemize}
\item How will the perception of the problem change for continuous formulation
of equations?
\item Will there be a case, when it is not valid to suppose, that for all
system parameters the optimal control strategy are still the same
through time?
\end{itemize}
At the end, we will discuss how can we use ideas from other works
or how to use the designed method in practical setting.

In the scope of this work, there will be developed an implementation
computing the values for an exact desired setting.




\section{Mathematical formulation}

This section will goadvance from writing the problem in terms of equations
to actually applying knowledge and methods for rewriting the problem.


\subsection{Formulation of the optimal control strategy}

Since we are using continuous formulation of equations, we are able
to follow the optimal control theory for continuous cases (thats one
difference from other works).


\paragraph{Model using power}

We need to rewrite the setting using mathematical formulation - to
express the boundary conditions, the state variables $x(t)$, the
performance index $J()$, the control function $u(t)$ and the dynamics
of the system $f(x,u,t)$ (using notation consistent with the optimal
control theory). 

Lets express every variable in energy, Joules, with exception for
$u_{2}$\nomenclature{$u_2$}{current flow from hydrogen $A$}, that
will be in ampers (see next).

Because we have two state variables - the state of charge of the accumulator
$B(t)$\nomenclature{$B(t)$}{energy stored in the accumulator $J$}
and the stored hydrogen $S(t)$\nomenclature{$S(t)$}{stored hydrogen $2F \cdot mol$}(in
the scripts the units are multiplied by Faradays constant times $n_{e}$
to not do conversion again for electrolyzer and fuelcell), our state
is two dimensional real valued function $x(t)=(x_{1}(t),x_{2}(t))=(B(t),S(t))$.
These quantities are bounded by $B(t)\leq B_{max}$\nomenclature{$B_{max}$}{maximal energy in battery $J$}
and $S(t)\leq S_{max}$\nomenclature{$S_{max}$}{maximum of hydrogen in tank $2F \cdot mol$},
bounds to maximal battery charge and maximal hydrogen stored (in means
of power we used to create the hydrogen). 

The boundary condition is $P_{src}(t)=P_{in}(t)-P_{demand}(t)$\nomenclature{$P_{src}$}{source power as energy from solar collectors minus electricity demand $W$},
difference between input power and power demand (so its units will
be Watts).

The control function $u$ is also a two dimensional function of time
and will define the power flow:
\begin{itemize}
\item the first component tells us about charging/discharging the battery:


\[
\dot{(B)}(t)=P_{batt}(u_{1})-\sigma B(t)
\]



Using this equation we can model the less than one efficiency by setting
$P_{batt}(u_{1})=u_{1}\eta_{batt}$ and the result of auto discharge
$\sigma$.
\begin{itemize}
\item $u_{1}>0$ ... We are charging the battery, using the power $u_{1}$.
There is a bound, how much power can we give to the battery $u_{1}\in[P_{batt+min},P_{batt+max}]$
\item $u_{1}=0$ ... Battery disconnected
\item $u_{1}<0$ ... We are discharging the battery, getting the power $-u_{1}$.
There is a bound, how much power we can get from battery $-u_{1}\in[P_{batt-min},P_{batt-max}]$
\end{itemize}
\item The second component tells us about the current flowing from the hydrogen
source:


\[
\dot{(S)}(t)=P_{H_{2}}(u_{2})
\]



Definitely the term will be different for $u_{2}$ positive and negative,
because this equation models two different devices:
\begin{itemize}
\item $u_{2}>0$ ... The electrolyzer is turned on, using the power$P_{H_{2}}(u_{2})$.
There is a bound, how much current can flow $u_{2}\in[P_{H_{2}+min},P_{H_{2}+max}]$
\item $u_{2}=0$ ... No change in hydrogen supply
\item $u_{2}<0$ ... The fuel cell is turned on, giving us the power $P_{H_{2}}(u_{2})$.
There is a bound, how much current we can get $-u_{2}\in[P_{H_{2}-min},P_{H_{2}-max}]$
\end{itemize}

Again, here we can model the efficiency (for example $P_{H_{2}}(u_{2})=\frac{N_{cell}u_{2}}{2F\eta_{F}}\eta_{H_{2}}$
for $u_{2}<0$ - the current would flow to the fuelcell, so we use
the equation for fuelcell times efficiency) and even nonlinear characteristics
of the efficiency. This design follows the wise rule, that the electrolyzer
and fuel cell should not operate simultaneously (because that would
be a waste of power). The bounds are, for example, the technical specifications
set by manufacturer. Why do we use current for $u_{2}$ and not power?
Because the model equations give us how the voltage depends on current
(and from that we can get the power dependency on current and thats
the function $P_{H_{2}}(u_{2})$).

\end{itemize}
Also in many cases in literature, the result of the analysis of the
optimal control problem is, that the actuall control function is so
called bang-bang control or bang-off-bang control. These controls
are called in this way, because they only use extreme allowed values
and zero (turned off). In our case it would not be wise to follow
this path, because the efficiency, in the means of power, varies.



So, once again and nicely written, the dynamics of our system is:
\begin{eqnarray*}
\dot{x} & = & f(x,u,t)\\
\dot{\left[\begin{array}{c}
B(t)\\
S(t)
\end{array}\right]} & = & \left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot B(t)\\
0
\end{array}\right]
\end{eqnarray*}
To finish our formulation, we want to find the minimizing control
function $u^{\star}$ (and the corresponding minimizing trajectory
$x^{\star}$ and costate $\lambda^{\star}$ - will be introduced later)
to minimize the performance index

\[
J=\phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt=hcost(S(T))+bcost(B(T))+\int_{0}^{T}pcost(P_{src}-P_{batt}-P_{H_{2}})\,dt
\]


where $hcost(x)$ is a function that gives a price for hydrogen,
$bcost(x)$, price for power in the battery and $pcost(x)$ is a function
that translates power exchange with the grid to its money cost. Generally
$pcost(0)=0,\,pcost(x)\cdot x\geq0,\,|pcost(x)|\leq|pcost(-x)|$ and
all the functions are bounded on bounded intervals.

That simply says, that for not using the grid we pay nothng, selling
gives us money, by buying we lose money and that selling the power
to grid would not give us such an amount of money as we would lose
by buying the power.

Generally we can think of any $pcost$ function, in the solution and
scripts below we will simply use $pcost(x)=c_{1}x\mbox{ if }x\geq0\mbox{, otherwise }=c_{2}x$,
for $c_{1},c_{2}\geq0$.

As we will see later, the most important thing is, that the function
$J[y]$ would be continuous.


\subparagraph{Note}

If we wanted to not optimize the cost, but the effectivity (in means
of power), we would simply use $L(x,u,t)=|P_{src}-P_{batt}-P_{H_{2}}|,\,\phi=0$.

Thats exactly the power, we are outputting to the net (or withdrawing
from) over selected time interval $[0,T]$. We are not interested
in the final value (even not in minimizing any function of the final
state) so it is classified as final state free problem.


\paragraph{Models for business problems}

As a note, every optimal control problem, whose aim is to find the
optimal strategy and the minimum of the functional, can be upgraded
so it can compute parameters for the most economic installation. The
adjustment is just adding parameters to the equation, that will allow
us to use components with different efficiency and tie these to a
cost. The cost, in turn, can then be added to the cost functional
(with keeping eye that then the physical units will become a currency
and making and adjustments) and the parameters can be also passed
to the numerical optimalizator.

For the testing run in the scripts attached, very simple models are
used, that bind the efficiency quadraticaly to cost (bounded on an
interval).




\subsubsection{Construction of solutions and rewriting the problem}

Now we will look at different formulations and used methods from the
literature, that will give us necessary conditions for minimality,
even from different views.


\paragraph{Hamiltonian}

The Hamiltonian of our system, using $\lambda\in\mathbb{R}^{2}$ as
lagrange multipliers is 
\begin{eqnarray*}
H(x,u,\lambda,t) & = & L(x,u,t)+\lambda^{T}f(x,u,t)\\
 & = & |P_{src}-P_{batt}-P_{H_{2}}|+\lambda_{1}(P_{batt}(u_{1})-\sigma\cdot B(t))+\lambda_{2}P_{H_{2}}(u_{2})
\end{eqnarray*}


By the way, because our state equations do not depend on time, our
Hamiltonian is constant. If we would include the fact that, for example,
the battery gets old and less efficient in time, the hamiltonian will
suddenly become non constant.



Additionally, in the presence of state constraints $x\in[0,B_{max}]\times[0,S_{max}]\iff\{x\in\mathbb{R}^{2},\,g(x)\le0,\,g(x)=-((x_{1}-\nicefrac{1}{2}B_{max})^{2}+\nicefrac{1}{4}B_{max}^{2})((x_{2}-\nicefrac{1}{2}S_{max})^{2}+\nicefrac{1}{4}S_{max}^{2})\}$,
we need to define a function $c(x,u)=\nabla g(x)\cdot f(x,u)$


\paragraph{Conditions for minimum}

Other (necessary) conditions for minimum are: (state equation, costate
equation, boundary conditions)

\begin{align*}
\dot{x} & =\frac{\partial H}{\partial\lambda}=f\tag*{...state equation}\\
-\dot{\lambda} & =\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\tag*{...costate equation}\\
x(t_{0}) & =(0,0)\tag*{...boundary condition}\\
(\phi_{x}+\psi_{x}^{T}\nu-\lambda)^{T}|_{T}dx+(\phi_{t}+\psi_{t}^{T}\nu+H)^{T}|_{T}dT & =0\tag*{...boundary condition prototype}\\
\lambda^{T}|_{T}dx+H^{T}|_{T}dT & =0\tag*{...boundary condition in our case\ensuremath{(dT=0)}}\\
\lambda_{i}(T) & =\frac{\partial\phi}{\partial x_{i}}(x(T),T)\tag*{...boundary condition for costate (for free final state)}\\
\lambda_{i}(T) & =0\tag*{...boundary condition for costate in our case}
\end{align*}





\paragraph{Pontryagin minimum principle}

Because values of control function are bounded (maybe even discrete
for degenerated intervals), we need to use Pontryagin maximum principle
(we are dealing with constrained input problem) “the Hamiltonian must
be minimized over all admissible $u$ for optimal values of the state
and costate.'' If we had continuous control function, the problem
could be tackled by more traditional approach using derivative of
Hamiltonian with respect to $u$.

In other words $H(x^{\star},u^{\star},\lambda^{\star},t)\geq H(x^{\star},u,\lambda^{\star},t)$
for all admissible $u$. (We have this instead of the stationary condition
$0=\frac{\partial H}{\partial u}=\frac{\partial L}{\partial u}+\frac{\partial f^{T}}{\partial u}\lambda$)

In the presence of state constraints, we have $ $ (instead of $-\dot{\lambda}=\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\mbox{ ...costate equation}$).


\paragraph{Hamilton Jacobi Bellman}



The equation for developement of the optimal cost (computed backwards)
is 
\begin{eqnarray*}
J^{\star}(x(T),T) & = & \phi(x(T),T)\\
-\frac{\partial J^{\star}}{\partial t} & = & \min_{u}H(x,u,J_{x}^{\star},t)=\min_{u}H(x,u,J_{x}^{\star},t)=L(x,u,t)+J_{x}^{\star}f(x,u,t)
\end{eqnarray*}


And to get $u^{\star}$ using HJB and Minimum principle:

\begin{eqnarray*}
u^{\star}(t,x,\lambda) & = & \arg\min_{u}(H(x,u,\lambda,t))\phi(x(T),T)
\end{eqnarray*}



\subsubsection{Approach using direct methods}

Above conditions for minimum come from the indirect approach. Allowing
countable number of discontinuities would rise the need to rewrite
the problem, as in \cite{gelfand1964calculus}. If we would like to
use direct methods with functions with discontinuities, the thoughts
will go in different way.


\paragraph{Ritz method, finite differences and existence}

As an important known result about direct methods, the direct way
to get to the minimum is the following (using \cite{gelfand1964calculus}
as a reference):

We construct an approximating sequence of spaces $\mathcal{M}_{i}$.
Each space $\mathcal{M}_{i}$ is defined by the basis functions $\{\varphi_{i}\}_{i=1}^{n}$,
such that their every linear combination $\sum^{n}\alpha_{i}\varphi_{i}$
together make the whole particular space $\mathcal{M}_{i}$. The sequence
of spaces will need to approximate (in subset sense $\mathcal{M}_{1}\subseteq...\subseteq\mathcal{M}_{i}\subseteq...\subseteq\mathcal{M}$)
the space $\mathcal{M}$ in which we would like the solution to lie.
This approach is called Ritz method.

Note, that the space $\mathcal{M}$ is likely to be infinite dimensional,
because the solution is, of course, a control function.

Approximating sequence of spaces is called complete, if, for any given
$y\in\mathcal{M}$ and $\epsilon>0$, we can have a function $y_{n}$
(of the form of linear combination) that differs less than epsilon
from the given function - $\left\Vert y_{n}-y\right\Vert <\epsilon$.

The convergence results then continue in this way:

If a functional $J[y]$, $y\in\mathcal{M}$ is continuous (in the
norm of the space $\mathcal{M}$) and if a sequence $\mathcal{M}_{i}$
is complete, then $\lim_{n\rightarrow\infty}\mu_{n}=\inf_{y}J[y]$
($\mu_{n}$'s are realized by functions $y_{n}\in\mathcal{M}_{n}$).

The finite differences idea then adds, that the approximation in each
particular space is done by piecewise linear function.

Together then, if we have a sequence ($y_{n}$), of optimal solutions
of our problem constrained to space $\mathcal{M}_{n}$, we are approaching
the limit if the given functional is continuous.

Does our problem, from the point of view of direct methods from calculus
of variations (``$J$ is cost function and $y$ is our$u,\,x,\,\lambda$''),
have this property?

Cost for our problem was given by:

\begin{eqnarray*}
J[x,u] & = & \phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt\\
 & = & hcost(S(u(T),x(T)))+bcost(B(u(T),x(T)))+\\
 &  & +\int_{0}^{T}pcost(P_{src}(x(t))-P_{batt}(u(t),x(t))-P_{H_{2}}(u(t),x(t)))\,dt
\end{eqnarray*}


And because everything comes down to functions $P_{batt}$ and $P_{H_{2}}$...
\begin{eqnarray*}
\dot{\left[\begin{array}{c}
B(t)\\
S(t)
\end{array}\right]} & = & \left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot B(t)\\
0
\end{array}\right]
\end{eqnarray*}
... that are selected to be continuous (see models presented before
- it is not only physically-wise selection that makes approximating
easier, computation faster, but it also gives us the needed results
here), we just need to clarify our demands on functions $hcost$,
$bcost$ and $pcost$ - to be continuous. Because these functions
just translate amouts of physical variable to cost in money, we can
assume continuity without causing any harm. 

In this analysis we ommited any constraints, but given the fact that
the constraints are, in the basic sense, constant, not dependent on
anything (because they just limit the maximal allowed powers of components),
they are not going to affect continuity in the presence of multipliers,
or any clever tricks meant to incorporate the multipliers (and they
also dont affect the existence of minima, because they constrain the
spaces on which we are searching for the minima).

Our functional is, in the end, easier to work with, than normally
presented problems from the calculus of variations, because we dont
have derivatives of the control function in our functional.



\begin{comment}
otazky

$\dot{x}=f(x,u,t):\dot{\left[\begin{array}{c}
SOC(t)\\
S(t)
\end{array}\right]}=\left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot SOC(t)\\
0
\end{array}\right]$ minimize the performance index $J=\int_{0}^{T}|P_{src}-P_{batt}-P_{H_{2}}|\,dt$

poznamky z konzultace s Kurzikem 14082014

nejdriv jestli to existuje jestli mi ty omezeni na rozsah nezkazi
existenci - to je potreba overit

v roubickove knize 260, relaxace proto abych to mohl resit

rizeni je z kompaktni mnoziny

box constraints minimalizuju funkci a 

gradientni metody jsou supr pro konvexni ulohu - tam vlastne vim ze
sem v minimu. Muze bejt lepsi druha mocnina kviuli kvadraticky strukture.
ta absolutni hodnota

v numerice to nebude hladky takze na gradient by byl problem, tam
by byla absolutni hodnota - takze lepsi kvadratickej, to muzu zkusit.

fortran - optimization tree mittleman - plato asu

----------->-Numericky kody brat z http://plato.la.asu.edu/bench.html<\textcompwordmark{}<---------------------------

---------------

OTAZKA - Jak vyjadrim, ze u (ridici funkce) a x (stavova promenna)
je omezene (nejakym uzavrenym intervalem)? Jak se to projevi na rovnicich?

OTAZKA - Jak postupovat dal? Jaky numericky resic (c++ idealne) se
da pouzit? Je jich hrozna hromada:

Hodi se dal posutpovat spis Hamilton jakobi bellmanem, dynamickym
programovanim s diskretizaci, nebo principem maxima? Co je nejlepsi
z hlediska programovyho/numerickyho nejrychlejsiho? Co se pouziva?

OTAZKY ohledne PDR a viskoznich reseni:

-OTAZKA jak resit pomoci HJB a vizkoznich reseni? Staci MKP? Jak na
to?

-OTAZKA - jsou viskozni reseni zobecneny slabyma resenima z nami zname
PDR 1?

otazka - Co znamenaji posledni podminky v optimal control strany 123

others

OTAZKA - jde nas problem vyresit jako linear quadratic regulator?
To pak ma analyzticky reseni! a nemusim diskretizovat.

protiOTAZKA - co by se zmenilo, kdybych tam dal absolutni hodnotu
misto kvadratu? otazka co by se zmenilo kdybych tam nemel kvadrat,
ale absolutni hodnotu v hodnotici funkci?

...
\end{comment}







\section{Implementation and results}

Using all previously mentioned, we developed a program answering following
question ``What is the most economic setting for photovoltaic and
hydrogen system and what is the specific power managment strategy
(the optimal control function) of such system?\textquotedbl{}. Lets
suppose, that we already have measured yearly power consumption and
have already installed photovoltaic panels and measured power output.
If it is not this case, we can, of course, use the model and approach
from \cite{Stand-alonePowerSystems} to get the estimated power output
from manufacturers datasheets.

Lets now have a look at all the implementation details and all the
used tools (because this way it would make the actual usage of the
scripts less time consuming work).


\subsection{Setting up the constants}

Two datasets standing for the boundary conditions of power consumption
and demand are supplied. The first data of generated solar energy
and house consumption were taken from this dataset \url{http://www.networkrevolution.co.uk/project-library/dataset-tc5-enhanced-profiling-solar-photovoltaic-pv-users/}
(using the monthly average averaged with weekday average for weekdays
and monthly average averaged with weekends average for weekends) and
through the scripts, the results are in a file \texttt{data.txt}.
The second dataset is a dataset that was also used in planning of
a real standalone system in the work \cite{VyrobaAVyuziti}, \texttt{data2.txt}.
(The first dataset was used in first experiments, in this text there
will be presented the data from the second dataset to allow comparsion.)

For setting the constants for electrolyzer and fuelcell empiric models,
we used the dataset \cite{Bauer:www.h2fc-fair.com} and a plot digitizer
software from \url{http://plotdigitizer.sourceforge.net/}. The model
parameters were fitted using MATLAB fitting toolbox (and from the
results below we can see, that the empiric models are indeed usefull
and sufficient). The source codes are in the directory ``fit\textquotedbl{}.

\begin{figure}
\includegraphics[width=0.45\textwidth]{fittedelectrolyzerplot}\includegraphics[width=0.45\textwidth]{fittedfuelcell}

\protect\caption{Results of the fitting for electrolyzer (left) and fuelcell (right),
x axis is current density ($mA\cdot m^{-2}$ ), y axis is voltage
($V$). Actual values of parameters are kept in the file \texttt{consts.m}
together with all the other model constants and numerical settings.}
\end{figure}



\subsection{The scripts and usage}

First attempt was to use the ACADO optimization toolkit. Even though
the scripts (and tests) were not able to run completely, the source
codes using this library are also attached, in the directory AcadoLinearVersion
(waiting for the next release of the toolkit).

The next step was to use MATLAB and to write multiple shooting algorithm
(as was said, in such a way, that they would reformulate the optimal
control problem as NLP problem), the formulation is independent on
actual solver used and so it is able to run with MATLABs original
fmincon function and with any algorithm from OPTI toolbox (\url{http://www.i2c2.aut.ac.nz/Wiki/OPTI/}).
In the case of algorithm breakdown on a specific problem setting,
we can just easily switch to different algorithm.

All used and tried approaches to the problem are reported with respective
sources in these directories:
\begin{itemize}
\item Directory \texttt{MatlabSinglShooting1} contains implementation using
single shooting technique. This implementation was not effective for
this problem.
\item In the main directory, there is implementation of multiple shooting
using MATLAB function fmincon.
\item Directory \texttt{TrySensitivity} contains the same problem implementation
with multiple shooting, but with employed sensitivity equations for
computing the derivatives. This approach has not proved to be working
effectively (probably because the precise computation of the derivatives
results in breakdown of the algorithm more often, than it did when
approximating them).
\item Directory \texttt{4dformulation} contains the code of a slightly differently
formulated problem, with 4 control functions (one for electrolyzer,
one for battery input, one for battery output and one for fuelcell)
in an attempt to try to cure said problem with derivatives, using
more dimensional problem, with only positive valued control functions
and more constraints. Unfortunately this approach failed, because
the resulting matrices in the computation were said to be badly conditioned.
\item Directory \texttt{Opti} contains the code for multiple shooting using
Opti toolbox solver.
\item Directory \texttt{AsBusiness} has sample scripts for optimization
of the cost - variables that influence the efficiency of the fuelcell
are added to the formulation, optimizer and final cost.
\end{itemize}
All the matlab scripts in each directory follow this structure:
\begin{itemize}
\item \texttt{main.m} - main file, executing in matlab will execute the
whole computation
\item \texttt{ctr.m} - function for computing the constraints (physical
and the ones resulting from multiple shooting approach)
\item \texttt{obj.m} - computing the objective function for optimization
\item \texttt{fun.m} - computing the whole equation, integration over the
time
\item \texttt{state.m} - evaluation of state equation
\item \texttt{statesens.m} - script for cimputing sensitivity equations
\item \texttt{consts.m} - file for storing the constants and options defining
the problem
\item \texttt{dispopt.m} - script for displaying graphs
\item \texttt{nlpoutfun.m} - script for displaying the approximations after
each iteration
\item \texttt{interpt1qr.m} - script for fast linear interpolation of the
source data
\item \texttt{controldata} - points on piecewise lienar function defining
the power demands
\end{itemize}
Every variation of the scripts can be run in the same manner - executing
\texttt{main.m}. The solved problem is set to examine the effectivity
over one year period. Because of this, you can also notice rescaling
constants in \texttt{consts.m} - because letting the integrators integrate
functions depending on very high time ranges in basic physical units
(seconds) would take unreasonable amount of time (aleso because the
boundary conditions are set to change on hour by hour basis and that
means that nothing interesting happens for the numerical integrator
that tries to watch for sudden changes and keep the precision).

For more discretization points the program becomes of course slower.
If you want to see some results earlier, you can set the constants
``Data.cLogBegin'' and ``Data.cLogEnd'' in \texttt{consts.m} to
specify at which power of two discretization points to begin and at
which to end. This also affects the selection of the initial values
- on the first run they are set randomly and on each consecutive run
they are copied from previous run (this is because the selection of
initial point in the search space can affect the outcome of certain
optimalizators and also their running time).

\begin{comment}
The program can operate in different modes:
\begin{enumerate}
\item global and control optimization - searches for the best setting against
costs using optimal control specific for each test case (i.e. runs
case 3. as a subroutine).
\item global optimization using PMS - searches for the best setting against
costs using only defined power managment strategies.
\item Simulation using optimal control - given the data, uses optimal control
algorithm to find optimal control for this one case
\item Simulation using PMS - given the data and PMS, simulates the system
\end{enumerate}
Source codes and program executables are attached in the electronic
version.
\end{comment}





\subsection{Results of test runs}

The scripts will start solving the problem on discretized control
function to number of discretization points beggining at $2^{\mbox{cLogBeg}}$
and ending at $2^{\mbox{cLogEnd}}$ (constants from \texttt{consts.m}),
copying the results from previous run to the next run. Some iterations
can fail to satisfy the bounds thinking that the problem is infeasible,
because at lower number of discretization points it can actually be
really difficult to achieve. Anyway it is automatically fixed when
the number of discretization points grows bigger. Then there will
be more decision points, that can steer the system to allowed set
of states.

After each iteration, matlab will show the state of the optimization
in 4 graphs, like in \prettyref{fig:1strun}. Left top graph shows
the state of energy in batter and hydrogen in tank, right top graph
shows the evolution of the cost function in time, left bottom graph
shows the control function (2 dimension - power to battery and current
to hydrogen - so two lines) and right bottom graph shows the state
trajectory. At the beginning, the results will look like in the figure
\ref{fig:1strun}, because the algorithm starts from a point far from
optimum. As for multiple shooting, the graph for states is not even
continuous, because the algorithm had not many iterations to guess
correctly the beginnnings of states.
\begin{figure}
\includegraphics[width=0.5\textwidth]{1stiter}\includegraphics[width=0.5\textwidth]{screenshotdal}\protect\caption{\label{fig:1strun}Algorithm results in progress. Axes are scaled
for better run of the algorithm. Less discretization points and early
stage (left, white), more discretization points and later stage (right,
gray).}


\end{figure}


For correct one-year long prediction, the optimization process would
take long time ($2^{14}$ discretization points would require more
than 4 days of processor time per iteration), so we would chose smaller
time scale for testing purposes - one week and $2^{8}$ discretization
points. 

Usually, the results suggest, that the algorithm fails, because it
is not able to even meet the provided conditions on such small scale
level - the power input and demand oscillates faster, than the number
of control points allows.

Also, the first numerical optimal control algorithm, that did not
undergo a breakdown on this problem was SQP (Sequential quadratic
programming), that is in line with the suggested approach in various
sources.



After 60 iterations, the algorithm starts converge to periodic decisions
copying the periodic boundary conditions. It is important to note,
that this first testing implementation should decide which algorithm
to implement on a paralellized architecture.


\paragraph{Summary}

We have summarized optimal control and fuel cells works and articles,
including deeper links to existence and uniqueness results. Then applied
a numerical optimal control method on a physical problem in a (so
far) unique way to get:
\begin{itemize}
\item a method for optimizing system (and system's cost) not against a certain
strategy, but against ideal maximum (which would work even better
in the need of control strategy change in runtime)
\item a method for comparing two strategies against ideal maximum - to allow
to answer a question whether we can get better, that cannot be otherwise
answered.
\item matlab implementation allowing for solver changes for testing different
minimum finding algorithms (in case of breakdowns)
\end{itemize}
Future work could include tuning the method for real applications
- the process would need to be implemented, for example, on a graphic
card or a computing cluster to be faster. Also given a reasonable
forecast of sunshine and power consumption, it could actually control
the system (by precalculating the control for the next week each specified
step in time), though this would need to be tested against (currently
considered) best power managment strategies. (Using previous forecast
as a starting point could make the calculation even faster.)


\subsection*{}

\pagebreak{}\printnomenclature
\addcontentsline{toc}{chapter}{Nomenclature}\pagebreak{}\listoffigures
\addcontentsline{toc}{chapter}{List of Figures}

\pagebreak{}

\bibliographystyle{alpha}
\phantomsection\addcontentsline{toc}{chapter}{\bibname}\bibliography{bibdata}
%\def\bibname{Bibliography}
%\begin{thebibliography}{99}
%\addcontentsline{toc}{chapter}{\bibname}
%\bibliography{bibdata} 
%\end{thebibliography}
\end{document}
