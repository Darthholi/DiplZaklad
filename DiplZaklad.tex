%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english,a4paper,english,czech,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{verbatim}
\usepackage{refstyle}
\usepackage{wrapfig}
\usepackage{calc}
\usepackage{units}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={2PDE},
 pdfauthor={Martin Holi Holecek}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.

\AtBeginDocument{\providecommand\figref[1]{\ref{fig:#1}}}
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}

\RS@ifundefined{subref}
  {\def\RSsubtxt{section~}\newref{sub}{name = \RSsubtxt}}
  {}
\RS@ifundefined{thmref}
  {\def\RSthmtxt{theorem~}\newref{thm}{name = \RSthmtxt}}
  {}
\RS@ifundefined{lemref}
  {\def\RSlemtxt{lemma~}\newref{lem}{name = \RSlemtxt}}
  {}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{amsthm,amsmath,amssymb,amscd,mathrsfs,url}
%\usepackage[czech]{babel}
\usepackage{verbatim}
%\usepackage{ictamxs}
\usepackage{showkeys}
\usepackage{xcolor}
\usepackage{stackengine}
\usepackage{lipsum}
\usepackage{comment}
%%\usepackage{MNsymbol} NIKDY!
\usepackage{graphicx}
\usepackage{caption}
\usepackage{nomencl}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage[customcolors,shade]{hf-tikz}
\usepackage{marginnote}
\usepackage{esint}
\usepackage{ulem}
\setlength\textwidth{145mm}
\setlength\textheight{247mm}
\setlength{\topmargin}{-2.3cm}          % HORNI ODSAZENI
\setlength{\textheight}{26.0cm}           % VYSKA STRANKY
\setlength{\textwidth}{18cm}          % SIRKA STRANKY, nebo pouzij: \addtolength{\textwidth}{4.0cm}
\addtolength{\oddsidemargin}{-2cm}    % POSUNUTI LEVEHO ODSAZENI, default for book=36mm%%
\addtolength{\evensidemargin}{-2cm}


\newcommand{\opdiv}{\mathop{\mathrm{div}}}
\newcommand{\oprot}{\mathop{\mathrm{rot}}}

\newcommand*\mnote[3][0pt]{%
  \if l#2\reversemarginpar\def\pointer{\filledmedtriangleright}%
    \def\stackalignment{r}\fi%
  \if r#2\normalmarginpar\def\pointer{\filledmedtriangleleft}%
    \def\stackalignment{l}\fi%
  \marginpar{%
    \topinset{%
      \scalebox{1.5}{\textcolor{blue}{$\pointer$}}}{%
      \belowbaseline[-1.5\baselineskip-#1]{%
        \stackengine%
          {-5pt}%
          {\fcolorbox{blue}{white}{\parbox{1.8cm}%
            {\vspace{3pt}\raggedright#3}}}%
          {~\colorbox{white}{\sffamily Pozn.}}%
          {O}%
          {l}%
          {F}%
          {F}%
          {S}%
        }%
      }{%
      3ex+#1}{%
      -2ex}%
  }%
}


\tikzstyle{mybox} = [draw=red, fill=blue!20, very thick,
    rectangle, rounded corners, inner sep=10pt, inner ysep=20pt]
\tikzstyle{fancytitle} =[fill=red, text=white]

\makenomenclature

\makeatother

\begin{document}

\title{Optimization of operation of renewable electric energy sources based
on fuel cells, accumulators and PV panels for small powers}

\maketitle

\part*{Motivation and introduction}

For better understanding of the whole problem and work, lets imagine
a model situation, that we can follow. Lets say, we want to make an
energy independent unit - ecologic house, for example.

Lets add renewable energy source (photovoltaic panels) and a system
for storing energy. Batteries alone are not sufficient, because they
would need to be changed, due to degradation. So lets add availible
hydrogen technologies - electrolyzer, hydrogen tank, fuel cells. And,
to finish the setting, backup energy unit (or electric grid). The
goal is to determine the system parameters (and develop the strategy
to do so) and power managment strategy in a manner to make the system
independent as much as possible (minimizing the consumption of backup
energy or energy from grid).

\begin{comment}
In this work not only do we want to solve this problem, but also to
make this text usefull for future coworkers,
\end{comment}


For now, lets look at the theoretical and practical tools needed to
solve this problem in the following part ``research and previous
works''. Later we will return to our model problem, and we will use
the tools to analyze the setting and rewrite it into mathematical
formulation. 

Lastly, there will be a brief note about the developed algorithms.

\begin{comment}
At our disposition we will have (or will develop) model for the system
with equations for parts of the system and supplying datas for daily
light current and energy demand.
\end{comment}
\begin{figure}[b]
\includegraphics[width=0.45\textwidth]{Schema-copy}\includegraphics[width=0.45\textwidth]{instalace}\protect\caption{Schema of functional units (left) and a photo of existing installation
in ÚJV Řež (right) \cite{UJVInst}}
\end{figure}



\part*{Research and previous works}

Lets look at other works and summarize interesting ideas from the
relevant fields.


\section*{Optimization and hydrogen technology}

Fuel cells and hydrogen technologies (as a part of renewable resources
\cite{RenewableSources}), extend the possibilities of energy storage
\cite{EnergyAccumulation} and create a possibility for research of
various systems using mathematical tools to model and optimize theese
systems. One example of such a system are standalone energetic units
\cite{MassimoStandalone}.

Some possibilities of optimization of theese standalone systems are
summarized in \cite{ErdincOptimumDesign}, optimization of standalone
energetic units and power managment strategies are being researched
too (in, for example \cite{IpsakisPowerManagmentStrategies}), and
some work is also focused on specific installations \cite{Abdelkafi20141},
\cite{Sarioglu20147}, \cite{Taher2014268}, \cite{Cai2014212}. Also
optimization problems are solved for vehicles \cite{Maalej2014668}.
In the article \cite{CaliseSingleLevel}, there is proposed an optimal
system even for the powerplant of SOFC (solid oxide fuel cell) type.

Fro mthe other side, application of optimization in the theory of
optimal control is described in the books \cite{EvansControlCourse},
\cite{Lewis2012optimal}, \cite{Warga1972optimal}. An example of
a method used for global optimization is an application of metropolis
algorithm, so called Simulated Annealing \cite{SimulatedAnnealing}
(that was originally used for the design of electric circuits or in
chemistry \cite{Chaudhuri1997733}). There is even a method taking
in account the uncertainity of data, Stochastic Annealing \cite{PaintonStochastic}.
This method is used in \cite{GiannakoudisOptimumDesign} for optimization
of the parameters of a control strategy.

Another interesting optimization principle, the Pontryagin principle,
is used to prolong the lifetime of such systems \cite{XuPontryaginStrategy,ProlongingLifetime,ZhengPontryaginProlonging}.

Needed to say, that new algorithms of global optimization are often
being used (ex. particle swarm, or genetic algorithms). For theese
algorithms, the question of convergence is still an open problem (about
this and another possibilities of such algorithms see the text \cite{ExperimentalAlgorithms}). 




\paragraph*{}


\section*{Models for batteries, fuel cells, electrolyzer, photovoltaics...}

There are rich availible model descriptions (for example also in \cite{vepa2013dynamic}),
complex models (with PDEs) are used for complicated problems and for
detailed desription of inside processes (for example in a battery),
but theese models arent meant and suited for simulations. More simple
models with less variables (for example like curve fitting) are better
in case we need to evaluate the model more times per run (as in our
case).


\subsection*{Photovoltaics}

When looking at photovoltaic (PV) panels, if we want a better model
than saying ``general power source\textquotedbl{}, we need to consider
that the photoelectric effect (the power source) happens at the P-N
junction, which is, of course, a diode, and that there is some ressistance
present. Thats the reason, why the following (\ref{fig:5-parameter-equivalent})
equivalent circuit ``5 parameter circuit\textquotedbl{} is used (there
exists even the so called ``7 parameter circuit\textquotedbl{} which
has another diode in parallel to the first diode). 

\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics{275px-Solar_cell_equivalent_circuit\lyxdot svg}\protect\caption{\label{fig:5-parameter-equivalent}5 parameter equivalent circuit
for photovoltaic panel}


\end{wrapfigure}%


Contruction details, like material used (single crystalline silicon,
polycrystalline and semicrystalline, thin films, amorphous silicon,
spheral...) or additional tricks (concentrated cells, lens, antireflexive
and other coating) affect the parameters and the efficiency. 

The circuit supplies current $I=I_{pv}$ at voltage $V=V_{pv}$, $I_{L}$
is generated current by photovoltaic effect and from that we subtract
diode current and shunt current. This way we can derive the model:
\begin{itemize}
\item $I_{pv}=I_{L}-I_{D}-I_{sh}=I_{L}-I_{0}(\exp(\frac{V_{pv}+I_{pv}R_{s}}{\alpha}))-\frac{V_{pv}+I_{pv}R_{s}}{R_{sh}}$\nomenclature{$I_{pv}$}{Current from photovoltaic model circuit ($A$)}
\item $I_{L}=C_{1}G,\,I_{0}=C_{2}T^{3}\exp(\frac{-E_{GO}}{kT})$
\item $P_{pv}=V_{pv}I_{pv}\eta_{conv}$ \nomenclature{$P_{pv}$}{Power from photovoltaic model circuit ($J$)}
\item $\alpha$ curve fitting parameter (model requires test runs and measurements)
\item $G$ incident radiation \nomenclature{$G$}{Incident radiation}
\item $T$ surface temperature
\item $E_{GO}$ band gap of the used PV material \nomenclature{$E_{GO}$}{band gap of the used PV material}
\item $C_{i}$ constants
\item $I_{L}$light current\nomenclature{$I_L$}{light current $A$}
\item $I_{D}$diode current \nomenclature{$I_{D}$}{diode current $A$}
\item $I_{sh}$shunt current \nomenclature{$I_{sh}$}{shunt current $A$}
\item $I_{0}$diode reverse saturation current (comes from the Shockley's
diode equation) \nomenclature{$I_{0}$}{diode reverse saturation current $A$}
\item $V_{pv}$, $I_{pv}$, operational voltage and current \nomenclature{$V_{pv}$}{operation voltage (photovoltaic) $V$}
\item $R_{s}$, $R_{sh}$, parallel and shunt ressistors \nomenclature{$R_{s}$}{parallel resistor ressistance $Ohm$}\nomenclature{$R_{sh}$}{shunt ressistor ressitance $Ohm$}
\item $P_{pv}$, $\eta_{conv}$ output power and effectivity \nomenclature{$\eta_{conv}$}{effectivity of photovoltaic output power}
\end{itemize}
Parameters used to characterize the output of the unit are short circuit
current, open circuit voltage and maximum power point. Nice derivation
is in the work \cite{Stand-alonePowerSystems} together with a method
on how to compute the parameters from manufacturer supplied information
from datasheet, notes on behavior with changing temperature, and finally
even a fortran code for PV panels. Also, the efficiency of PV energy
generation is said to be from 5 to 20\%. 

In a work focused on solar panels and water electrolysis \cite{olubukunmi2011solar},
there is deeper description and analysis and measurement of output
power dependency on illumination and even thermal effects.

Needed to say, that detailed analysis of output power includes an
observation \cite{voutetakis2011design}, that there is a maximal
power point in the voltage current characteristic; this is ideally
exploited by a microcontroller, traking this point. (In addition this
book covers many interesting details, even about AC/DC converters.)
Algorithms for tracking maximal power point are also being developed
in \cite{beyer2004robust,salas2006review}, also using neural networks
is considered \cite{caluianu2011photovoltaic}.






\subsection*{Battery}

Why to use both batteries and hydrogen (tanks) to store energy? Batteries
have higher efficiency, but cant store as much energy as we can with
hydrogen. Moreover, the state of charge of batteries tends to decrease
and batteries tends to lose quality over time. But using them as quick
source, or buffer of energy, is generally a good idea. Moreover, in
a case, where electrolyzer works better at lower loads, battery can
lower the load by taking it on itself.

\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics[scale=0.2]{EqivLeadAcid}\protect\caption{Equivalent circuit for lead acid accumulator.}
\end{wrapfigure}%


The main variables for a battery model are the voltage and state of
charge (SOC). Lets speak about a model of lead acid accumulator from
\cite{voutetakis2011design} - the model is valid for batteries charged
more than 20 \%, has relations for charging and discharging and parameters
that need to becomputed experimentally. (Needed to say, that there
exists models even for overcharged batteries and other specific cases.)

\[
I_{bat}=I_{q}-\frac{Q_{bat,nom}}{10}g_{0}exp(\frac{V_{cell}}{g_{1}}-\frac{g_{2}}{T_{bat}})
\]
\nomenclature{$I_{bat}$}{battery current $A$}

The battery current is the reaction current ($I_{q}$) minus the gas
current loses, that are modelled using nominal capacity of accumulator
($Q_{bat,nom}$ in $Ah$), cell voltage, temperature and gassing current
parameters. The cell voltage is the equillibrium plus polarization
voltage:

\[
V_{cell}=V_{equ,0}+\frac{V_{equ,l}SOC}{100}+V_{pol}
\]
\nomenclature{$V_{cell}$}{cell voltage $V$}

The equillibrium voltage is approximated linearily by its value at
$SOC=0$ and slope $V_{equ,l}$, the polarization voltage is different
for charging and discharging (with coefficients dependent on the battery):

\begin{eqnarray*}
V_{pol,ch} & = & U_{ch}a_{ch}(1-\exp(-\frac{I_{q,norm}}{b_{ch}})+c_{ch}I_{q,norm})\\
V_{pol,dch} & = & U_{dch}(1-\exp(-\frac{I_{q,norm}}{b_{dch}})+c_{dch}I_{q,norm})(1+(g_{100}-1)\exp(\frac{SOC-100}{k_{100}}))
\end{eqnarray*}
\nomenclature{$V_{pol,ch}$}{charging polarization voltage $V$}\nomenclature{$V_{pol,dch}$}{discharging polarization voltage}

The indexes ``ch\textquotedbl{} stand for charging and ``dch\textquotedbl{}
for discharging. The parameters $g_{100},k_{100}$ are height and
slope parametes for fully charged battery ($SOC=100\%$).

A discrete model for a capacity of the battery is 
\[
Q_{bat,i}=Q_{bat,i-1}+I_{q}(t_{i}-t_{i-1})=Q_{bat,nom}SOC_{i-1}/100+I_{q}(t_{i}-t_{i-1})
\]
\nomenclature{$Q_{bat.i}$}{battery capacity $J$}

The state of charge of the accumulator is a fraction of the current
capacity at each time instant divided by its nominal capacity. So
for $SOC$ we have a model with efficiency ($\eta_{ac}$)\nomenclature{$\eta_{ac}$}{battery efficiency},
discharge rate ($\sigma_{ac}$)\nomenclature{$\sigma_{ac}$}{battery discharge rate}
and charge or discharge current $I_{ac}$\nomenclature{$I_{ac}$}{battery current (charge or discharge)}.

\[
SOC(t+1)=SOC(t)(1-\sigma_{ac})+I_{ac}\eta_{ac}(\Delta t)
\]


$SOC$ cannot be directly measured, it needs to be derived from the
model or indirectly from experiements.\nomenclature{$SOC$}{battery state of charge}




\subsection*{Electrolyzer and Fuel cell}

Electrolyzer and fuel cell both basically operate from a simple chemical
reaction (\cite{rayment2003introduction}) :

\[
H_{2}O\longleftrightarrow H_{2}+\frac{1}{2}O_{2}
\]


By adding (electric) power, the reaction occurs from left side to
the right, producing hydrogen and oxygen, whereas combining hydrogen
and oxygen allows us to get the energy back. The first way is the
basic function of electrolyzer and the latter is of the fuel cell.
By Faradays law, the (molar) quantity of produced/consumed hydrogen
is proportional to transfered charge.

Interesting details arise from the exact engeneering of both processes
(parameters like temperature, material of electrolyte or membrane,
catalyzators etc...), anyway the basic common variables are voltage,
current and temperature.

It is good to note, that hydrogen has the best heating value (energy
to fuel ratio). The higher heating value is $142.12\,MJ\,kg^{-1}$,
the pure standart heat formation of the product water. The lower heating
value is $120.21\,MJ\,kg^{-1}$, calculated from the fact, that the
product oxygen goes out unused as a steam (at said $150$ \textdegree C
). Electrolysis is not the only way to get hydrogen, other ways are
being considered too, for example by reforming natural gases.


\subsubsection*{Electrolyzer}

Common types of electrolyzers are alkaline based (operates using an
alkaline solution) and proton exchange membrane electrolyzer (PEM).

As presented in \cite{voutetakis2011design}, there are many ways
to the voltage-current model of the electrolyzer: regression, models
based on analysis of processes on anothe, cathode and membrane (and
calculating then V-I relationship by subtracting from the open circuit
voltage the voltages of activation polarization and ohmic polarization),
and even rigorous CFD models.


\paragraph*{Butler Volmer equation}

In the work \cite{Stand-alonePowerSystems}, it is noted, that at
low voltages, the electrolyzer is more efficient, but generates small
amounts of hydrogen. The Butler-Volmer equation is used to model the
system:

\[
I=I_{0e}(\exp(\frac{(1-\alpha_{e})n_{e}F}{RT}(U-U_{eq}))-\exp(-\frac{\alpha_{e}n_{e}F}{RT}(U-U_{eq})))
\]


With unknown parameters $I_{0e}$, $\alpha_{e}$ (symmetry factor)
and$U_{eq}$. Hydrogen production rate is computed as follows: \nomenclature{$n_{H_2}$}{hydrogen production rate ($\frac{mol}{hr \cdot A}$)}

\[
n_{H_{2}}=\frac{N_{cell}I_{elec}}{n_{e}F}\eta_{F}
\]
\nomenclature{$N_{cell}$}{number of cells}\nomenclature{$I_{elec}$}{current through electrolyzer $A$}\nomenclature{$\eta_F$}{Faraday efficiency}

where $F$ is Faraday constant and $\eta_{F}$ is Faraday efficiency
(relation between theoretical and actual electron transfer, often
to be determined by experimental measure), $n_{e}=2$ \nomenclature{$n_e$}{Electrons in $H_2$}.



\paragraph*{One empirical model}

\[
V_{elec}=V_{rev,elec}+\frac{r_{1}+r_{2}T}{A_{elec}}I_{elec}+(s_{1}+s_{2}T+s_{3}T^{2})\log(\frac{t_{1}+t_{2}/T+t_{3}/T^{2}}{A_{elec}}I_{elec}+1)
\]
\nomenclature{$V_{elec}$}{electrolyzer voltage $V$}\nomenclature{$A_{elec}$}{area of electrolyzer $m^2$}

This model takes into account the dependency on temperature (\cite{voutetakis2011design}).
There exists even empirical model for the faraday's efficiency, that
takes into account the fact, that with decreasing current and/or higher
temperatures, the parasitic currents increase (because of the electrolyte).

\[
\eta_{F}=B_{1}+B_{2}\exp(\frac{B_{3}+B_{4}T_{el}+B_{5}T_{el}^{2}}{i})
\]
\nomenclature{$i$}{area current $A/m^2$}




\subsubsection*{Fuel cell}

The exact process happens in this way:

\begin{eqnarray*}
H_{2} & \rightarrow & 2H^{+}+2e^{-}\\
\frac{1}{2}O_{2}+2e^{-} & \rightarrow & O^{2-}\\
2H^{+}+O^{2-} & \rightarrow & H_{2}O
\end{eqnarray*}


And the calculation (from \cite{olubukunmi2011solar}) for the amount
of hydrogen produced is:

\[
n_{H_{2}}=\frac{1}{\epsilon}\cdot0,01866\frac{mol}{hr\cdot A},\,m_{H_{2}}=\frac{1}{\epsilon}\cdot3,77\cdot10^{-5}\frac{kg}{hr\cdot A}
\]
\nomenclature{$m_{H_2}$}{hydrogen production rate (kilograms instead of mols) $\frac{kg}{hr \cdot A}$}...
where $\epsilon$ is the fuel cell efficiency:

The simplest way to model fuel cell V-I relationship is to look at
it as a reverse electrolyzer, this direction is followed by the following
model from \cite{voutetakis2011design}.


\paragraph*{First empiric model}

Takes into account the overvoltages (ohmic and activation), but not
effects of mass. The model computes the cell voltage $V_{fc}$\nomenclature{$V_{fc}$}{fuel cell voltage $V$}
using open circuit voltage $V_{o}$\nomenclature{$V_{o}$}{open circuit voltage for fuel cell $V$},
current density $i$, model parameter $b$, current at the inflection
point of the V-I curve $I_{d}$ and slope $\Delta$ at the linear
stage of ohmic overvoltage:\nomenclature{$I_{d}$}{current at inflection point in fuelcell V-I curve }

\[
V_{fc}=E+\frac{b}{\ln(1/I_{d}\,i)}-(\Delta-\frac{b}{4I_{d}})\,i
\]


The parameters ($K\in\{E,\,I_{d},\,b,\,\Delta\}$) \nomenclature{$K$}{general notation for one parameter in empiric model for fuelcells}
vary with fuel cell temperature $T$ and oxygen partial pressue $p_{O_{2}}$:\nomenclature{$p_{O_2}$}{oxygen partial pressue}

\[
K=K_{1}+K_{2}T+K_{3}T\ln(p_{O_{2}})
\]


It is said, that this model is suitable more for low voltages and
powers. But it can be used even for electrolyzer ($p_{O_{2}}$ is
then the operating pressue for the electrolyzer at which the oxygen
is produced).


\paragraph*{Second empiric model}

This model takes into effect even the mass transport limitation. For
computation of a cell voltage $V_{fc}$ and open circuit voltage $V_{o}$,
the following applies:

\begin{eqnarray*}
V_{fc} & = & V_{o}-a_{T}\log(i)-ir+m\exp(il)\\
V_{o} & = & V_{rev,FC}+B\log(i_{o})
\end{eqnarray*}


Where $V_{rev,FC}$ \nomenclature{$V_{rev,fc}$}{fuelcell, reversible voltage}is
the reversible voltage, $i$ the current density (fuel cell current
per unit area of the electrode, in units of milliamps per square centimeter),$i_{0}$
and $B$ the Tafel parameter ($i_{0}$is the value on the Tafel plot
when the current begins to move away from zero), $a_{T}$ the Tafel
slope, $r$ the resistance (in $\Omega\cdot cm^{2}$), finally the
model parameters $m$, $l$ representing the overvoltage due to mass
transport limits. All theese parameters can depend on temperature.

Hydrogen and oxygen then flows according to this equations (by Faradays
law):

\[
H_{2,g}=\frac{N_{cell}I}{2F\eta_{F}},\,O_{2,g}=\frac{N_{cell}I}{4F\eta_{F}}
\]


All these models are empirical and are important only because of their
low computational complexity. For greater complexity, there are of
course more sophisticated models using partial differential equations.
There is also a nice book about fuel cells, that examines every aspect
of fuel cell design and explains the details of how fuel cells works
\cite{larminie2003fuel}.

Lets add a word about the storage of hydrogen. The possibilities for
storage are to store it at the output pressue of the electrolyzer,
or at higher pressue or liquidified. Theese possibilities are covered
in most of presented resources and citations. If we wanted to store
the hydrogen in any other way than at the output pressue, we would
need to add the compressor into the equation (like it is done in \cite{voutetakisdesign}).




\section*{\pagebreak{}}


\section*{Optimization and optimal control}



Optimization is a rich field with many subproblems arising from the
specific problems settings. Optimal control actually is applied optimization
together with variational calculus \cite{milyutin1999calculus} and
has similar subproblems (or subclasses).

As (global) optimization is concerned about finding the minimum of
a function with number of parameters, optimal control theory takes
this idea to the next step and solves minimum of a functional (``objective
function'' or ``cost function\textquotedbl{} $J$ that consists
of final time objective and integrated Lagrangian) of a dynamic system,
evolving in time, controlled by a function (system dynamics).

\begin{align*}
\mbox{minimize}\,J & =\phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt\tag*{...cost function / objective function}\\
\dot{x} & =f(x,u,t)\tag*{...system dynamics}\\
x(0) & =x_{0}\\
g(x,u,t) & \leq0\tag*{...constraints}
\end{align*}


In free final time, the function $\phi$ is not present.

Problems from calculus of variations can be formulated as an optimal
control problem, so the ideas from this field apply in optimal control
too. Moreover, optimal control theory has methods for solving the
problem of controllability and observability and the presence of noise.


\subsubsection*{Basic terms}

Optimization problems have many subclasses (\ref{fig:Optimization-Tree})
and optimal control is not an exception.\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics[width=0.5\textwidth]{treeoptimiz}\protect\caption{\label{fig:Optimization-Tree}Optimization Tree, neos.mcs.anl.gov}
\end{wrapfigure}%




So, in formulating the problem, there are many decisions that need
to be made, or many features, that can be adressed. To get a grasp
of the field, lest summarize the most common features. (More details
can be found in the book \cite{bertsekas1995dynamic} and the developement
of this field over time is summarized in the article \cite{sargent2000optimal}).

First, the problem can be formulated in \textbf{finite time} or \textbf{infinite
time}, or the \textbf{time can be varied} too (``free time, fixed
endpoint'' problem vs ``fixed time free endpoint''). The model
can be\textbf{ continuous} or \textbf{discrete}, not only in \textbf{time,
but also in states}. Lastly, we can account for \textbf{statistical
uncertainities}. When we add probabilty to the problem, we will be
dealing with markov chains theory.

The goal, control policy, can be made \textbf{open loop} or \textbf{closed
loop} formulation. Closed loop does care for values and decisions
in intermediate states, whereas open loop control has the control
function predetermined in advance and not relying on intermedate states
and values. Methods for solving optimal control problems are \textbf{dynamic
programming}, \textbf{Hamilton Jacobi Bellman (HJB) equations} and
\textbf{Pontryagin maximum principle} (or minimum principle, it doesn't
matter and is called by both names in literature). Only some of the
problems can be solved analytically, for example the class of \textbf{linear
quadratic control} problems, that can be solved through Riccati equations.

Long story short, there are two main approaches - direct methods and
indirect methods. Indirect methods take the optimal control problem
and reformulate it as differential equation problem with possible
boundary conditions - this approach is best used for continuous functions,
of course. Direct methods view the problem as a problem of nonlinear
programming

Both approaches are supported by the strength of calculus of variations
\cite{gelfand1964calculus} and both approaches are actually used
in numerical solutions.


\subsubsection*{Hamiltonian of the system}

Many problem formulations could be efficiently written using Hamiltonian
of the system. We will use it too, so lets state the Hamiltonian as
a Lagrangian (from cost function) plus adjoint variable times system
dynamics.

\begin{eqnarray*}
H(x,u,\lambda,t) & = & L(x,u,t)+\lambda^{T}f(x,u,t)
\end{eqnarray*}


Said efficiency comes from the fact, that the system dynamics is a
sort of a constraint and we translate constrained optimization problem
to unconstrained - the adjoint variable comes from this idea to introduce
lagrangian multipliers (as in \cite{EvansControlCourse,Lewis2012optimal,bryson1975applied})
or from HJB equations (there are two ways to get the equations presented
later, one gives the name ``adjoint variable\textquotedbl{} to one
of the derivatives, so it is conveniet to use the name). It is essential
for formulations, that will come later. Lets just note here, that
Hamiltonian is constant for systems with parametres undependent on
time.

To summarize, the problem is then to optimize the vallue of Hamiltonian
- finding such optimal control function $u$, state function $x$
and costate function $\lambda$.\nomenclature{$u$}{usuall notation for control function}\nomenclature{$x$}{usuall notation for state}\nomenclature{$\lambda$}{usual notation for costate}


\subsubsection*{Dynamic programming}

Dynamic Programming is a principle well known for problems, that can
be decomposed into smaller subproblems. The principle is easy - if
the optimal solution of a problem can be composed from optimal solutions
of subproblems, we can use this information to build the solution.
Whenever this is true (needs for example additive cost function),
we just dont need to search the whole state space, but we can construct
the solution by constructing subsolutions one from another in a clever
order. One example from other field is the problem of finding the
shortest path in a graph.

Dynamic programming needs discretized problem formulation. And going
to the limit with discretization points gives rise to the HJB equations.


\subsubsection*{Hamilton-Jakobi-Bellman equations}

HJB eq. are partial differential equations of the problem (here we
need the Hamiltonian), the last equation is just system dynamic written
using Hamiltonian:

\begin{align*}
J^{\star}(x(T),T) & =\phi(x(T),T)\\
-\frac{\partial J^{\star}}{\partial t} & =\min_{u}H(x,u,J_{x}^{\star},t)=\min_{u}H(x,u,J_{x}^{\star},t)=L(x,u,t)+J_{x}^{\star}f(x,u,t)\\
\dot{x} & =\frac{\partial H}{\partial\lambda}=f\tag*{...state equation}
\end{align*}


When using this apporach, the first step is to solve to get the optimal
value function first and from that the other values. Hamilton-Jakobi-Bellman
equations from optimal control gave life to the theory of viscosity
solutions, more can be found in articles \cite{bardi2008optimal,dragoniintroduction,liu2013introduction}.
Theese equations can be solved using finite element methods, but their
stability is said not to be good.


\subsubsection*{Pontryagin principle of maximality, PMP}

The last step - or method - principle of maximality (Pontryagin principle
of maximality, PMP), can be - for continuous control functions - derived
using the HJB equations (as in \cite{bertsekas1995dynamic}). Using
that, we get to formulate equations for adjoint variable - the first
equation is pontryagin maximum principle and the second we get by
differentiating HJB equation, as in \cite{diehl2011numerical}. The
last condition is the transversality condition for fixed time free
endpoint problem.



\begin{align*}
u^{\star}(t,x,\lambda) & =\arg\min_{u}(H(x,u,\lambda,t))\phi(x(T),T)\\
-\dot{\lambda} & =\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\\
\lambda(T) & =\nabla\phi(x(T),T)
\end{align*}




As was said, we get the same results even from the perspective of
taking the system dynamic as constraint for lagrange multipliers.

In the presence of state constraints $x\in R=\{x\in\mathbb{R}^{n},\,g(x)\le0\}$,
PMP is formulated a bit differently \cite{EvansControlCourse} - we
need to define a function 
\[
c(x,u)=\nabla g(x)\cdot f(x,u)
\]
 and the costate equation becomes: 
\[
-\dot{\lambda}=\frac{\partial H}{\partial x}(x,u,t)+\mu\frac{\partial c}{\partial x}(x,u)
\]
While the PMP now states the existence of the function $\mu:\,[0,T]\rightarrow\mathbb{R}$.

Needed to say, that PMP equations are only necessary condition for
optimality, so analytical proof of existence and uniqueness is needed.


All theese analytic methods will give us equations, to solve the equations
is a concern of numerical optimal control.


\subsection*{Numerical optimal control}

Numerical optimal control can be, again, used to solve continuous
or discretized problems. Heavily relies on the problem analysis and
follows the said methods. It would seem, that it is sufficient to
just solve HJB PDR's, but it is not used everytime. For example, the
problem is, so called, curse of dimensionality - when state and/or
control, has many components, the problem becomes exponentially hard
to solve. Suggested remedy, in the article \cite{diehl2011numerical},
is, for example, to approximate value function by neural network methods.
 Second guide, to know when to use state and costate equations, is,
that when we want to have continuous control function, we can just
solve the boundary value problem (as in, for example, \cite{wang2009solving}).
When we want to allow discontinuities, we need to rewrite the problem
to nonlinear optimization problem (an excellent book about this topic
is \cite{chachuat2007nonlinear}).



\begin{figure}
\fbox{\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item HJB Equations - tabulation in state space
\item Indirect methods, Pontryagin - solve boundary value problem
\item Direct Methods - change to nonlinear programming

\begin{itemize}
\item Single shooting - discretized controls to NLP
\item Multiple shooting - controls and node start values discretized
\item Collocation - disretized controls and states\end{itemize}
\end{itemize}
%
\end{minipage}}

\protect\caption{Numerical optimal control cases}
\end{figure}


As said above, the main classes are \textbf{indirect methods} (first
optimize then discretize) and \textbf{direct methods} (first discretize,
then optimize). Indirect methods results in algorithms similar to
ODE solvers, but the resulting system can be badly conditioned or
unstable. Direct methods just rewrite the problem to the area of nonlinear
programming problem and then apply convenient solver.

There are three main cases of direct methods - single shooting, Multiple
shooting and collocation.

Single shooting discretizes the control to piecewise constant function
and uses numerical integrator for the evaluation of the cost function
(ODE). This way we get a finite dimensional optimization problem,
which can be solved by any nonlinear programming algorithm \cite{OptcontrNLP},
more in section below.

Single shooting algorithm is usefull, but the stability can sometimes
depend heavily on starting value.

Collocation discretizes both the control function and state function
and approximates the integral. We get larger system for nonlinear
programming, but the good news is that the system is sparse (in the
meaning, that the Jacobian has many zero elements). Collocation can
treat better even unstable systems, but refining the grid results
in new problem with higher dimensions.

Multiple shooting discretizes the control, as single shooting, and
additionally the time scale. So it is called ``multiple'' shooting,
because it works like running single shooting algorithm again from
the starting times $t_{i}$. Of course we need to add constraints
for continuity (the end values from the previous interval to be the
same as the starting values on the next interval). Multiple shooting
is only block sparse, but is easy to paralelize and can treat even
unstable systems well.

Numerous implementations of numerical optimal control are availible,
not only in MATLAB, but for example also in C++ in \cite{Houska2011a}.


\paragraph*{Nonlinear programming (NLP)}

Is an area of algorithms for optimizing nonlinear cost functions (on
constrained and unconstrained sets). Methods include derived algorithms
from ideas of gradient descend or newton method (applied on finding
a point where the gradient is zero), for example. Usually these methods
can also make use of derivatives (with said newton method on forst
derivative we, for example, need also second derivatives) and that,
in case of optimal control and optimizing differential equations,
leads to the need of computing sensitivity equations. That means how
the functional depends on the choice of (discretized) control function
$\frac{\partial J}{\partial u_{i}}$. When not supplied, methods usually
compute these just by approximating. Algoritmical approaches for getting
the results for sensitivity are, for example External Numerical Differentiation
(END), Variational Differential Equations, Automatic Differentiation,
Internal Numerical Differentiation (IND) (that makes use of the equations
written directly in source code for numerical computation).

More details about computing sensitivity equations are for example
in \cite{Sensitivity20061553}.

Also a suggested technique is, for example, Sequential quadratic programming,
SQP, \cite{boggs1995sequential}, \cite{ottanumerical}. It is a method
for solving nonlinear problems with second derivatives; uses repeated
subsolutions of quadratic programming problems.

\pagebreak{}


\part*{Solution}

In this section we will apply the theory and methods to our setting
and problem (trying to focus on issues, that were not answered in
other works).


\paragraph*{Contribution of this work}

Now, lets emphasize, that other existing works tried to model the
problem using discontinuous functions and optimized only the system
parameters (for minimial cost) for given power managment strategy
or optimized only the the power managment strategy (or decision constants
of the said strategy).

So our aim will be to optimize the global parameters against the cost
(using global optimization algorithms) but for each test case (values
of variables) use the methods of optimal control theory to find the
best control strategy. That can be usefull in cases, where we wonder
about the follwing:
\begin{itemize}
\item How will the perception of the problem change for continuous formulation
of equations?
\item Will there be a case, when it is not valid to suppose, that for all
system parameters the optimal control strategy are still the same
through time?
\end{itemize}
At the end, we will discuss how can we use ideas from other works
(for example to switch from Simulated Annealing to Stochastic annealing)
or how to use the designed method in practical setting.

In the scope of this work, there will be developed an implementation
computing the values for an exact desired setting.




\section*{Mathematical formulation}

This section will go smoothly from writing the problem in terms of
equations to actually applying knowledge and methods for rewriting
the problem.


\subsection*{Formulation of the optimal control strategy}

Since we are using continuous formulation of equations, we are able
to follow the optimal control theory for continuous cases (thats one
difference from other works).


\paragraph*{Model using power}

We need to rewrite the setting using mathematical formulation - to
express the boundary conditions, the state variables $x(t)$, the
performance index $J()$, the control function $u(t)$ and the dynamics
of the system $f(x,u,t)$ (using notation consistent with the optimal
control theory). 

Lets express every variable in energy, Joules, with exception for
$u_{2}$\nomenclature{$u_2$}{current flow from hydrogen $A$}, that
will be in ampers (see next).

Because we have two state variables - the state of charge of the accumulator
$B(t)$\nomenclature{$B(t)$}{energy stored in the accumulator $J$}
and the stored hydrogen $S(t)$\nomenclature{$S(t)$}{stored hydrogen $2F \cdot mol$}(in
the scripts the units are multiplied by Faradays constant times $n_{e}$
to not do conversion again for electrolyzer and fuelcell), our state
is two dimensional real valued function $x(t)=(x_{1}(t),x_{2}(t))=(B(t),S(t))$.
Theese quantities are bounded by $B(t)\leq B_{max}$\nomenclature{$B_{max}$}{maximal energy in battery $J$}
and $S(t)\leq S_{max}$\nomenclature{$S_{max}$}{maximum of hydrogen in tank $2F \cdot mol$},
bounds to maximal battery charge and maximal hydrogen stored (in means
of power we used to create the hydrogen). 

The boundary condition is $P_{src}(t)=P_{in}(t)-P_{demand}(t)$\nomenclature{$P_{src}$}{source power as energy from solar collectors minus electricity demand $W$},
difference between input power and power demand (so its units will
be Watts).

The control function $u$ is also a two dimensional function of time
and will define the power flow:
\begin{itemize}
\item the first component tells us about charging/discharging the battery:


\[
\dot{(B)}(t)=P_{batt}(u_{1})-\sigma B(t)
\]



Using this equation we can model the less than one efficiency by setting
$P_{batt}(u_{1})=u_{1}\eta_{batt}$ and the result of auto discharge
$\sigma$.
\begin{itemize}
\item $u_{1}>0$ ... We are charging the battery, using the power $u_{1}$.
There is a bound, how much power can we give to the battery $u_{1}\in[P_{batt+min},P_{batt+max}]$
\item $u_{1}=0$ ... Battery disconnected
\item $u_{1}<0$ ... We are discharging the battery, getting the power $-u_{1}$.
There is a bound, how much power can we get from battery $-u_{1}\in[P_{batt-min},P_{batt-max}]$
\end{itemize}
\item The second component tells us about the current flowing from the hydrogen
source:


\[
\dot{(S)}(t)=P_{H_{2}}(u_{2})
\]



Definitely the term will be different for $u_{2}$ positive and negative,
because this equation models two different devices:
\begin{itemize}
\item $u_{2}>0$ ... The electrolyzer is turned on, using the power$P_{H_{2}}(u_{2})$.
There is a bound, how much current can flow $u_{2}\in[P_{H_{2}+min},P_{H_{2}+max}]$
\item $u_{2}=0$ ... No change in hydrogen supply
\item $u_{2}<0$ ... The fuel cell is turned on, giving us the power $P_{H_{2}}(u_{2})$.
There is a bound, how much current we can get $-u_{2}\in[P_{H_{2}-min},P_{H_{2}-max}]$
\end{itemize}

Again, here we can model the efficiency (for example $P_{H_{2}}(u_{2})=\frac{N_{cell}u_{2}}{2F\eta_{F}}\eta_{H_{2}}$
for $u_{2}<0$ - the current would flow to the fuelcell so we use
the equation for fuelcell times efficiency) and even nonlinear characteristics
of the efficiency. This design follows the wise rule, that the electrolyzer
and fuel cell should not operate simultaneously (because that would
be a waste of power). The bounds are, for example, the technical specifications
set by manufacturer. Why do we use current for $u_{2}$ and not power?
Because the model equations give us how the voltage depends on current
(and from that we can get the power dependency on current and thats
the function $P_{H_{2}}(u_{2})$).

\end{itemize}
Also in many cases in literature, the result of the analysis of the
optimal control problem is, that the actuall control function is so
called bang-bang control or bang-off-bang control. These controls
are called in this way, because they only use extreme allowed values
and zero (turned off). In our case it would not be wise to follow
this path, because the efficiency, in the means of power, varies.



So, once again and nicely written, the dynamics of our system is:
\begin{eqnarray*}
\dot{x} & = & f(x,u,t)\\
\dot{\left[\begin{array}{c}
B(t)\\
S(t)
\end{array}\right]} & = & \left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot B(t)\\
0
\end{array}\right]
\end{eqnarray*}
To finish our formulation, we want to find the minimizing control
function $u^{\star}$ (and the corresponding minimizing trajectory
$x^{\star}$ and costate $\lambda^{\star}$ - will be introduced later)
to minimize the performance index

\[
J=\phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt=hcost(S(T))+bcost(B(T))+\int_{0}^{T}pcost(P_{src}-P_{batt}-P_{H_{2}})\,dt
\]


where $hcost(x)$ is a function that gives a price for hydrogen,
$bcost(x)$, price for power in the battery and $pcost(x)$ is a function
that translates power exchange with the grid to its money cost. Generally
$pcost(0)=0,\,pcost(x)\cdot x\geq0,\,|pcost(x)|\leq|pcost(-x)|$ and
all the functions are bounded on bounded intervals.

That simply says, that for not using the grid we pay nothng, selling
gives us money, by buying we lose money and that selling the power
to grid would not give us such an amount of money as we would lose
by buying the power.

Genrally we can think of any $pcost$ function, in the solution and
scripts below we will simply use $pcost(x)=c_{1}x\mbox{ if }x\geq0\mbox{, otherwise }=c_{2}x$,
for $c_{1},c_{2}\geq0$.

As we will see later, the most important thing is, that the function
$J[y]$ would be continuous.


\subparagraph*{Note}

If we wanted to not optimize the cost, but the effectivity (in means
of power), we would simply use $L(x,u,t)=|P_{src}-P_{batt}-P_{H_{2}}|,\,\phi=0$.

Thats exactly the power, we are outputting to the net (or withdrawing
from) over selected time interval $[0,T]$. We are not interested
in the final value (even not in minimizing any function of the final
state) so it is classified as final state free problem.


\paragraph*{Models for business problems}

As a note, every optimal control problem, whose aim is to find the
optimal strategy and the minimum of the functional, can be upgraded
so it can compute parameters for the most economic installation. The
adjustment is just adding parameters to the equation, that will allow
us to use components with different efficiency and tie these to a
cost. The cost, in turn, can then be added to the cost functional
(with keeping eye that then the physical units will become a currency
and making and adjustments) and the parameters can be also passed
to the numerical optimalizator.

For the testing run in the scripts attached, very simple models are
used, that bind the efficiency quadraticaly to cost (bounded on an
interval).




\subsubsection*{Construction of solutions and rewriting the problem}

Now we will look at different formulations and used methods like in
literature, that will give us necessary conditions for minimality,
even from different views.


\paragraph*{Hamiltonian}

The Hamiltonian of our system, using $\lambda\in\mathbb{R}^{2}$ as
lagrange multipliers is 
\begin{eqnarray*}
H(x,u,\lambda,t) & = & L(x,u,t)+\lambda^{T}f(x,u,t)\\
 & = & |P_{src}-P_{batt}-P_{H_{2}}|+\lambda_{1}(P_{batt}(u_{1})-\sigma\cdot B(t))+\lambda_{2}P_{H_{2}}(u_{2})
\end{eqnarray*}


By the way, because our state equations do not depend on time, our
Hamiltonian is constant. If we would include, that, for example, the
battery gets old and less efficient in time, the hamiltonian will
suddenly become non constant.



Additionally, in the presence of state constraints $x\in[0,B_{max}]\times[0,S_{max}]\iff\{x\in\mathbb{R}^{2},\,g(x)\le0,\,g(x)=-((x_{1}-\nicefrac{1}{2}B_{max})^{2}+\nicefrac{1}{4}B_{max}^{2})((x_{2}-\nicefrac{1}{2}S_{max})^{2}+\nicefrac{1}{4}S_{max}^{2})\}$,
we need to define a function $c(x,u)=\nabla g(x)\cdot f(x,u)$


\paragraph*{Conditions for minimum}

Other (necessary) conditions for minimum are: (state equation, costate
equation, boundary conditions)

\begin{align*}
\dot{x} & =\frac{\partial H}{\partial\lambda}=f\tag*{...state equation}\\
-\dot{\lambda} & =\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\tag*{...costate equation}\\
x(t_{0}) & =(0,0)\tag*{...boundary condition}\\
(\phi_{x}+\psi_{x}^{T}\nu-\lambda)^{T}|_{T}dx+(\phi_{t}+\psi_{t}^{T}\nu+H)^{T}|_{T}dT & =0\tag*{...boundary condition prototype}\\
\lambda^{T}|_{T}dx+H^{T}|_{T}dT & =0\tag*{...boundary condition in our case\ensuremath{(dT=0)}}\\
\lambda_{i}(T) & =\frac{\partial\phi}{\partial x_{i}}(x(T),T)\tag*{...boundary condition for costate (for free final state)}\\
\lambda_{i}(T) & =0\tag*{...boundary condition for costate in our case}
\end{align*}





\paragraph*{Pontryagin minimum principle}

Because values of control function are bounded (maybe even discrete
for degenerated intervals), we need to use Pontryagin maximum principle
(we are dealing with constrained input problem) “the Hamiltonian must
be minimized over all admissible $u$ for optimal values of the state
and costate.'' If we had continuous control function, the problem
could be tackled by more traditional approach using derivative of
Hamiltonian with respect to $u$.

In other words $H(x^{\star},u^{\star},\lambda^{\star},t)\geq H(x^{\star},u,\lambda^{\star},t)$
for all admissible $u$. (We have this instead of the stationary condition
$0=\frac{\partial H}{\partial u}=\frac{\partial L}{\partial u}+\frac{\partial f^{T}}{\partial u}\lambda$)

In the presence of state constraints, we have $ $ (instead of $-\dot{\lambda}=\frac{\partial H}{\partial x}=\frac{\partial f^{T}}{\partial x}\lambda+\frac{\partial L}{\partial x}\mbox{ ...costate equation}$).


\paragraph*{Hamilton Jacobi Bellman}



The equation for developement of the optimal cost (computed backwards)
is 
\begin{eqnarray*}
J^{\star}(x(T),T) & = & \phi(x(T),T)\\
-\frac{\partial J^{\star}}{\partial t} & = & \min_{u}H(x,u,J_{x}^{\star},t)=\min_{u}H(x,u,J_{x}^{\star},t)=L(x,u,t)+J_{x}^{\star}f(x,u,t)
\end{eqnarray*}


And to get $u^{\star}$ using HJB and Minimum principle:

\begin{eqnarray*}
u^{\star}(t,x,\lambda) & = & \arg\min_{u}(H(x,u,\lambda,t))\phi(x(T),T)
\end{eqnarray*}



\subsubsection*{Approach using direct methods}

Above conditions for minimum come from the indirect approach (and
allowing countable number of disconiuities would rise the need to
rewrite the problem, as in \cite{gelfand1964calculus}). If we would
like to use direct methods with functions with discontiuities, the
thoughts will go in different way.


\paragraph*{Ritz method, finite differences and existence}

As a note about direct methods using \cite{gelfand1964calculus} as
a reference, the direct way to get to the minimum is the following:

We construct a sequence of spaces $\mathcal{M}_{i}$. Each space $\mathcal{M}_{i}$
is defined by basis functions $\{\varphi_{i}\}_{i=1}^{n}$, such that
their every linear combination $\sum^{n}\alpha_{i}\varphi_{i}$ then
make the whole particular space $\mathcal{M}_{i}$. The sequence of
spaces will be needed to approximate $\mathcal{M}_{1}\subseteq...\subseteq\mathcal{M}_{i}\subseteq...\subseteq\mathcal{M}$
the space $\mathcal{M}$ in which we would like the solution to lie.
This is called the Ritz Method.

Note that the space $\mathcal{M}$ is likely to be infinite dimensional,
because the solution is of course a control function.

Such a sequence of spaces is called complete, if for any given $y\in\mathcal{M}$
and $\epsilon>0$ we can have a function $y_{n}$ (of the form of
linear combination) that differs less than epsilon from the given
function - $\left\Vert y_{n}-y\right\Vert <\epsilon$.

The convergence result is then like this:

If a functional $J[y]$, $y\in\mathcal{M}$ is continuoous (in the
norm of the space $\mathcal{M}$) and if a sequence $\mathcal{M}_{i}$
is complete, then $\lim_{n\rightarrow\infty}\mu_{n}=\inf_{y}J[y]$
($\mu_{n}$'s are realized by functions $y_{n}\in\mathcal{M}_{n}$).

The finite differences idea then says, that the approximation in each
particular space is done by piecewise linear function.

Together then, if we have a sequence ($y_{n}$) of optimal solutions
of our problem - constrained to space $\mathcal{M}_{n}$, then we
are approaching the limit if the given functional is continuous.

So, does our problem, from the point of view of direct methods from
calculus of variations (such a point of view means, that $J$ is cost
function and $y$ is our$u,\,x,\,\lambda$), have this property?

Cost for our problem was given by

\begin{eqnarray*}
J[x,u] & = & \phi(x(T),T)+\int_{0}^{T}L(x,u,t)\,dt\\
 & = & hcost(S(u(T),x(T)))+bcost(B(u(T),x(T)))+\\
 &  & +\int_{0}^{T}pcost(P_{src}(x(t))-P_{batt}(u(t),x(t))-P_{H_{2}}(u(t),x(t)))\,dt
\end{eqnarray*}


So, given the fact, that everything comes down to functions $P_{batt}$
and $P_{H_{2}}$
\begin{eqnarray*}
\dot{\left[\begin{array}{c}
B(t)\\
S(t)
\end{array}\right]} & = & \left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot B(t)\\
0
\end{array}\right]
\end{eqnarray*}
... that are selected to be continuous (see models up there - it is
not only physically-wise selection that makes approximating easier,
computation faster, but it also gives us the needed results here),
we just need to clarify our demands on functions $hcost$, $bcost$
and $pcost$ - to be continuous. Because these functions just translate
amouts of physical variable to cost in money, we can assume continuity
without causing any harm. 

In this analysis we ommited any constraints, but given the fact that
the constraints are, in the basic sense, constant, not dependent on
anything (because they just limit the maximal allowed powers of components),
they are not gonna affect continuity in the presence of multipliers,
or any clever tricks meant to incorporate them (and they also dont
affect the existence of minima, because they constrain the spaces
on which we are finding the minima).

Our functional is, in the end, easier to work with, than normal problems
from the calculus of variations, because we dont have derivations
of the constrol function in our functional.



\begin{comment}
otazky

$\dot{x}=f(x,u,t):\dot{\left[\begin{array}{c}
SOC(t)\\
S(t)
\end{array}\right]}=\left[\begin{array}{c}
P_{batt}(u_{1})\\
P_{H_{2}}(u_{2})
\end{array}\right]+\left[\begin{array}{c}
-\sigma\cdot SOC(t)\\
0
\end{array}\right]$ minimize the performance index $J=\int_{0}^{T}|P_{src}-P_{batt}-P_{H_{2}}|\,dt$

poznamky z konzultace s Kurzikem 14082014

nejdriv jestli to existuje jestli mi ty omezeni na rozsah nezkazi
existenci - to je potreba overit

v roubickove knize 260, relaxace proto abych to mohl resit

rizeni je z kompaktni mnoziny

box constraints minimalizuju funkci a 

gradientni metody jsou supr pro konvexni ulohu - tam vlastne vim ze
sem v minimu. Muze bejt lepsi druha mocnina kviuli kvadraticky strukture.
ta absolutni hodnota

v numerice to nebude hladky takze na gradient by byl problem, tam
by byla absolutni hodnota - takze lepsi kvadratickej, to muzu zkusit.

fortran - optimization tree mittleman - plato asu

----------->-Numericky kody brat z http://plato.la.asu.edu/bench.html<\textcompwordmark{}<---------------------------

---------------

OTAZKA - Jak vyjadrim, ze u (ridici funkce) a x (stavova promenna)
je omezene (nejakym uzavrenym intervalem)? Jak se to projevi na rovnicich?

OTAZKA - Jak postupovat dal? Jaky numericky resic (c++ idealne) se
da pouzit? Je jich hrozna hromada:

Hodi se dal posutpovat spis Hamilton jakobi bellmanem, dynamickym
programovanim s diskretizaci, nebo principem maxima? Co je nejlepsi
z hlediska programovyho/numerickyho nejrychlejsiho? Co se pouziva?

OTAZKY ohledne PDR a viskoznich reseni:

-OTAZKA jak resit pomoci HJB a vizkoznich reseni? Staci MKP? Jak na
to?

-OTAZKA - jsou viskozni reseni zobecneny slabyma resenima z nami zname
PDR 1?

otazka - Co znamenaji posledni podminky v optimal control strany 123

others

OTAZKA - jde nas problem vyresit jako linear quadratic regulator?
To pak ma analyzticky reseni! a nemusim diskretizovat.

protiOTAZKA - co by se zmenilo, kdybych tam dal absolutni hodnotu
misto kvadratu? otazka co by se zmenilo kdybych tam nemel kvadrat,
ale absolutni hodnotu v hodnotici funkci?

...
\end{comment}







\section*{Implementation and results}

Using all previously mentioned, we developed a computer program answering
following question ``What is the most economic setting for photovoltaic
and hydrogen system and what is the power managment strategy (the
optimal control function) of such system?\textquotedbl{}. Lets suppose,
that we already have measured yearly power consumption and have already
installed photovoltaic panels and measured power output. If it is
not this case, we can, of course, use the model and approach from
\cite{Stand-alonePowerSystems} to get the estimated power output
from manufacturers datasheets.

Lets now have a look at all the implementation details and all the
used tools (because this way it would make the actual usage of the
scripts less time consuming work).


\subsection*{Setting up the constants}

The data of generated solar energy and house consumption were taken
from this dataset \url{http://www.networkrevolution.co.uk/project-library/dataset-tc5-enhanced-profiling-solar-photovoltaic-pv-users/}
(using the monthly average averaged with weekday average for weekdays
and monthly average averaged with weekends average for weekends) and
through the scripts, the results are in a file data.txt.

For setting the constants for electrolyzer and fuelcell empiric models,
we used the dataset \cite{Bauer:www.h2fc-fair.com} and a plot digitizer
software from \url{http://plotdigitizer.sourceforge.net/}. The model
parameters were fitted using MATLAB fitting toolbox (and from the
results below we can see, that the empiric models are indeed usefull
and sufficient). The source codes are in the directory ``fit\textquotedbl{}.

\begin{figure}
\includegraphics[width=0.45\textwidth]{fittedelectrolyzerplot}\includegraphics[width=0.45\textwidth]{fittedfuelcell}

\protect\caption{Results of the fitting for electrolyzer (left) and fuelcell (right),
x axis is current density ($mA\cdot m^{-2}$ ), y axis is voltage
($V$). Actual values of parameters are kept in the file \texttt{consts.m}
together with all the other model constants and numerical settings.}
\end{figure}



\subsection*{The scripts and usage}

First attempt was to use the ACADO optimization toolkit. Even though
the scripts (and tests) were not able to run completely, the source
codes using this library are also attached, in the directory AcadoLinearVersion
(waiting for the next release of the toolkit).

The next step was to use MATLAB and to write multiple shooting algorithm
(as was said, in such a way, that they would reformulate the optimal
control problem as NLP problem), the formulation is independent on
actual solver used and so it is able to run with MATLABs original
fmincon function and with any algorithm from OPTI toolbox (\url{http://www.i2c2.aut.ac.nz/Wiki/OPTI/}).

All used and tried approaches to the problem are reported with respective
sources in these directories:
\begin{itemize}
\item Directory \texttt{MatlabSinglShooting1} contains implementation using
single shooting technique. This implementation was not effective for
this problem.
\item In the main directory, there is implementation of multiple shooting
using MATLAB function fmincon.
\item Directory \texttt{TrySensitivity} contains the same problem implementation
with multiple shooting, but with employed sensitivity equations for
computing the derivatives. This approach has not proved to be working
effectively (probably because the precise computation of the derivatives
results in breakdown of the algorithm more often, than it did when
approximating them).
\item Directory \texttt{4dformulation} contains the code of a slightly differently
formulated problem, with 4 control functions (one for electrolyzer,
one for battery input, one for battery output and one for fuelcell)
in an attempt to try to cure said problem with derivatives, using
more dimensional problem, with only positive valued control functions
and more constraints. Unfortunately this approach failed, because
the resulting matrices in the computation were said to be badly conditioned.
\item Directory \texttt{Opti} contains the code for multiple shooting using
Opti toolbox solver.
\item Directory \texttt{AsBusiness} has sample scripts for optimization
of the cost - variables that influence the efficiency of the fuelcell
are added to the formulation, optimizer and final cost.
\end{itemize}
All the matlab scripts in each directory follow this structure:
\begin{itemize}
\item \texttt{main.m} - main file, executing in matlab will execute the
whole computation
\item \texttt{ctr.m} - function for computing the constraints (physical
and the ones resulting from multiple shooting approach)
\item \texttt{obj.m} - computing the objective function for optimization
\item \texttt{fun.m} - computing the whole equation, integration over the
time
\item \texttt{state.m} - evaluation of state equation
\item \texttt{statesens.m} - script for cimputing sensitivity equations
\item \texttt{consts.m} - file for storing the constants and options defining
the problem
\item \texttt{dispopt.m} - script for displaying graphs
\item \texttt{nlpoutfun.m} - script for displaying the approximations after
each iteration
\item \texttt{interpt1qr.m} - script for fast linear interpolation of the
source data
\item \texttt{controldata} - points on piecewise lienar function defining
the power demands
\end{itemize}
Every variation of the scripts can be run in the same manner - executing
\texttt{main.m}. The solved problem is set to examine the effectivity
over one year period. Because of this, you can also notice rescaling
constants in \texttt{consts.m} - because letting the integrators integrate
functions depending on very high time ranges in basic physical units
(seconds) would take unreasonable amount of time (aleso because the
boundary conditions are set to change on hour by hour basis and that
means that nothing interesting happens for the numerical integrator
that tries to watch for sudden changes and keep the precision).

For more discretization points the program becomes of course slower.
If you want to see some results earlier, you can set the constants
``Data.cLogBegin'' and ``Data.cLogEnd'' in \texttt{consts.m} to
specify at which power of two discretization points to begin and at
which to end. This also affects the selection of the initial values
- on the first run they are set randomly and on each consecutive run
they are copied from previous run (this is because the selection of
initial point in the search space can affect the outcome of certain
optimalizators and also their running time).

\begin{comment}
The program can operate in different modes:
\begin{enumerate}
\item global and control optimization - searches for the best setting against
costs using optimal control specific for each test case (i.e. runs
case 3. as a subroutine).
\item global optimization using PMS - searches for the best setting against
costs using only defined power managment strategies.
\item Simulation using optimal control - given the data, uses optimal control
algorithm to find optimal control for this one case
\item Simulation using PMS - given the data and PMS, simulates the system
\end{enumerate}
Source codes and program executables are attached in the electronic
version.
\end{comment}





\subsection*{Results of test runs}

The scripts will start solving the problem on discretized control
function to number of discretization points beggining at $2^{\mbox{cLogBeg}}$
and ending at $2^{\mbox{cLogEnd}}$ (constants from \texttt{consts.m}),
copying the results from previous run to the next run. Some iterations
can fail to satisfy the bounds thinking that the problem is infeasible,
because at lower number of discretization points it can actually be
really difficult to achieve. Anyway it is automatically fixed when
the number of discretization points grows bigger. Then there will
be more decision points, that can steer the system to allowed set
of states.

After each iteration, matlab will show the state of the optimization
in 4 graphs, like in \figref{1strun}. Left top graph shows the state
of energy in batter and hydrogen in tank, right top graph shows the
evolution of the cost function in time, left bottom graph shows the
control function (2 dimension - power to battery and current to hydrogen
- so two lines) and right bottom graph shows the state trajectory.
At the beginning, the results will look like in the figure, because
the algorithm starts from a point far from optimum. As for multiple
shooting, the graph for states is not even continuous, because the
algorithm had not many iterations to guess correctly the beginnnings
of states.\begin{wrapfigure}{o}{0.5\columnwidth}%
\includegraphics[width=0.5\textwidth]{1stiter}\protect\caption{\label{fig:1strun}Algorithm results in progress. Axes are scaled
for better run of the algorithm.}
\end{wrapfigure}%



\subsection*{}


\subsubsection*{}

\pagebreak{} \printnomenclature \pagebreak{}\listoffigures


\pagebreak{}

\bibliographystyle{alpha}
\phantomsection\addcontentsline{toc}{section}{\refname}\bibliography{bibdata}

\end{document}
